import React, { useState } from 'react';
import '../../css/Systems.css';

interface AITopic {
  name: string;
  details: string[];
}

const topics: AITopic[] = [
  {
    name: 'Supervised Learning',
    details: [
      '🎯 Definition: Trains on labeled input-output pairs to learn mapping f: X → Y',
      '📊 Goal: Make accurate predictions on new, unseen data',
      '',
      '🔢 LINEAR REGRESSION:',
      '   Formula: y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε',
      '   Cost Function: MSE = (1/2m) Σ(hθ(x⁽ⁱ⁾) - y⁽ⁱ⁾)²',
      '   Example: Predicting house prices based on size, location, bedrooms',
      '   Visual: Straight line fitting through data points',
      '',
      '📈 LOGISTIC REGRESSION:',
      '   Formula: p = 1/(1 + e^(-z)) where z = β₀ + β₁x₁ + ... + βₙxₙ',
      '   Cost Function: J(θ) = -(1/m)[Σy⁽ⁱ⁾log(hθ(x⁽ⁱ⁾)) + (1-y⁽ⁱ⁾)log(1-hθ(x⁽ⁱ⁾))]',
      '   Example: Email spam detection (spam=1, not spam=0)',
      '   Visual: S-shaped sigmoid curve',
      '',
      '🎯 SUPPORT VECTOR MACHINE (SVM):',
      '   Formula: f(x) = sign(ΣαᵢyᵢK(xᵢ,x) + b)',
      '   Objective: max margin = 2/||w||',
      '   Kernel Trick: K(x,z) = φ(x)ᵀφ(z) (RBF: K(x,z) = exp(-γ||x-z||²))',
      '   Example: Image classification, text categorization',
      '   Visual: Hyperplane separating classes with maximum margin',
      '',
      '🌳 DECISION TREES:',
      '   Split Criterion: Gini = 1 - Σpᵢ² or Entropy = -Σpᵢlog₂(pᵢ)',
      '   Information Gain: IG = H(parent) - Σ(|child|/|parent|)H(child)',
      '   Example: Medical diagnosis (fever>38°C → cold vs flu)',
      '   Visual: Tree structure with if-then rules',
      '',
      '🌲 RANDOM FOREST:',
      '   Formula: ŷ = (1/B)ΣTᵦ(x) for regression, majority vote for classification',
      '   Bootstrap: Sample with replacement, use √p features per split',
      '   Example: Credit scoring, feature importance ranking',
      '   Visual: Multiple trees voting on final prediction',
      '',
      '🧠 NEURAL NETWORKS:',
      '   Forward Pass: aˡ = σ(Wˡaˡ⁻¹ + bˡ)',
      '   Backpropagation: ∂C/∂w = δᵃˡ⁻¹ᵀ, δˡ = (Wˡ⁺¹)ᵀδˡ⁺¹ ⊙ σ\'(zˡ)',
      '   Activation: ReLU = max(0,x), Sigmoid = 1/(1+e⁻ˣ), Tanh = (eˣ-e⁻ˣ)/(eˣ+e⁻ˣ)',
      '   Example: Image recognition, natural language processing',
      '   Visual: Layered network of interconnected nodes',
      '',
      '🎲 K-NEAREST NEIGHBORS (KNN):',
      '   Distance: Euclidean = √Σ(xᵢ-yᵢ)², Manhattan = Σ|xᵢ-yᵢ|',
      '   Prediction: Majority vote (classification) or average (regression) of k neighbors',
      '   Example: Recommendation systems, pattern recognition',
      '   Visual: Points clustered around similar neighbors',
      '',
      '📋 EVALUATION METRICS:',
      '   Accuracy = (TP+TN)/(TP+TN+FP+FN)',
      '   Precision = TP/(TP+FP), Recall = TP/(TP+FN)',
      '   F1-Score = 2×(Precision×Recall)/(Precision+Recall)',
      '   ROC-AUC: Area under Receiver Operating Characteristic curve'
    ]
  },
  {
    name: 'Unsupervised Learning',
    details: [
      '🔍 Definition: Discovers hidden patterns in unlabeled data without target variables',
      '🎯 Goal: Find structure, reduce dimensions, group similar data points',
      '',
      '🎯 K-MEANS CLUSTERING:',
      '   Algorithm: Minimize WCSS = ΣΣ||xᵢ - μⱼ||² where μⱼ is centroid j',
      '   Steps: 1) Initialize k centroids 2) Assign points 3) Update centroids 4) Repeat',
      '   Distance: Euclidean = √Σ(xᵢ-yᵢ)²',
      '   Example: Customer segmentation, market research, image compression',
      '   Visual: Points grouped around k cluster centers',
      '',
      '🌲 HIERARCHICAL CLUSTERING:',
      '   Agglomerative: Bottom-up, merge closest clusters',
      '   Divisive: Top-down, split clusters recursively',
      '   Linkage: Single (min), Complete (max), Average, Ward (minimize variance)',
      '   Example: Phylogenetic trees, social network analysis',
      '   Visual: Dendrogram showing cluster hierarchy',
      '',
      '🎯 DBSCAN (Density-Based):',
      '   Core Point: |N(p)| ≥ minPts within ε radius',
      '   Border Point: In ε-neighborhood of core point',
      '   Noise Point: Neither core nor border',
      '   Example: Anomaly detection, irregular cluster shapes',
      '   Visual: Dense regions connected, outliers as noise',
      '',
      '📐 PRINCIPAL COMPONENT ANALYSIS (PCA):',
      '   Formula: Y = XW where W are eigenvectors of covariance matrix',
      '   Variance Explained: λᵢ/Σλⱼ for eigenvalue λᵢ',
      '   Steps: 1) Standardize 2) Covariance matrix 3) Eigendecomposition 4) Project',
      '   Example: Image compression, data visualization, feature reduction',
      '   Visual: Data projected onto principal component axes',
      '',
      '📊 t-SNE (t-Distributed Stochastic Neighbor Embedding):',
      '   High-D Similarity: pⱼ|ᵢ = exp(-||xᵢ-xⱼ||²/2σᵢ²)/Σₖ≠ᵢexp(-||xᵢ-xₖ||²/2σᵢ²)',
      '   Low-D Similarity: qᵢⱼ = (1+||yᵢ-yⱼ||²)⁻¹/Σₖ≠ₗ(1+||yₖ-yₗ||²)⁻¹',
      '   Cost: KL(P||Q) = ΣᵢΣⱼpᵢⱼlog(pᵢⱼ/qᵢⱼ)',
      '   Example: High-dimensional data visualization, gene expression',
      '   Visual: Non-linear embedding preserving local structure',
      '',
      '🛒 ASSOCIATION RULES (Market Basket):',
      '   Support: sup(A) = |A|/|D| (frequency of itemset A)',
      '   Confidence: conf(A→B) = sup(A∪B)/sup(A)',
      '   Lift: lift(A→B) = conf(A→B)/sup(B)',
      '   Apriori Algorithm: Generate frequent itemsets, extract rules',
      '   Example: "People who buy bread also buy butter" (grocery stores)',
      '   Visual: Network of item associations with strength indicators',
      '',
      '🎯 GAUSSIAN MIXTURE MODELS (GMM):',
      '   Formula: p(x) = Σₖπₖ𝒩(x|μₖ,Σₖ) where πₖ are mixing coefficients',
      '   EM Algorithm: E-step (responsibilities), M-step (parameters)',
      '   Log-likelihood: ℓ = Σᵢlog(Σₖπₖ𝒩(xᵢ|μₖ,Σₖ))',
      '   Example: Image segmentation, density estimation',
      '   Visual: Overlapping Gaussian distributions forming clusters',
      '',
      '🌐 UNIFORM MANIFOLD APPROXIMATION (UMAP):',
      '   Theory: Riemannian manifold learning with topological data analysis',
      '   Fuzzy Simplicial Sets: Probabilistic topology representation',
      '   Optimization: Cross-entropy between high/low dimensional representations',
      '   Example: Single-cell genomics, large-scale data visualization',
      '   Visual: Preserves both local and global structure better than t-SNE',
      '',
      '📋 EVALUATION METRICS:',
      '   Silhouette Score: (b-a)/max(a,b) where a=intra, b=inter cluster distance',
      '   Davies-Bouldin Index: (1/k)Σᵢmaxⱼ≠ᵢ(σᵢ+σⱼ)/d(cᵢ,cⱼ) (lower is better)',
      '   Calinski-Harabasz: Between-cluster variance / Within-cluster variance',
      '   Elbow Method: Plot WCSS vs k, find "elbow" point'
    ]
  },
  {
    name: 'Reinforcement Learning',
    details: [
      '🎮 Definition: Agent learns optimal actions through trial-and-error interactions with environment',
      '🏆 Goal: Maximize cumulative reward over time through optimal policy π*',
      '🔑 Core Elements: State (S), Action (A), Reward (R), Policy (π), Value (V)',
      '',
      '📊 MARKOV DECISION PROCESS (MDP):',
      '   Components: <S, A, P, R, γ> (States, Actions, Transitions, Rewards, Discount)',
      '   Bellman Equation: V*(s) = max_a Σs\' P(s\'|s,a)[R(s,a,s\') + γV*(s\')]',
      '   Policy: π(a|s) = probability of taking action a in state s',
      '   Visual: State-action diagram with transition probabilities',
      '',
      '🎯 Q-LEARNING (Model-Free):',
      '   Update Rule: Q(s,a) ← Q(s,a) + α[r + γmax_a\'Q(s\',a\') - Q(s,a)]',
      '   ε-Greedy: Choose random action with probability ε, else argmax_a Q(s,a)',
      '   Convergence: Guaranteed if all state-action pairs visited infinitely often',
      '   Example: Game playing (Pac-Man), robot navigation',
      '   Visual: Q-table with state-action values, policy derived from max Q-values',
      '',
      '🔄 SARSA (State-Action-Reward-State-Action):',
      '   Update Rule: Q(s,a) ← Q(s,a) + α[r + γQ(s\',a\') - Q(s,a)]',
      '   On-Policy: Updates based on actual policy being followed',
      '   Difference from Q-Learning: Uses actual next action a\' instead of max',
      '   Example: Safe robot control, conservative exploration',
      '   Visual: Agent follows policy while learning, more conservative updates',
      '',
      '🧠 DEEP Q-NETWORKS (DQN):',
      '   Neural Network: Q(s,a;θ) ≈ Q*(s,a) where θ are network parameters',
      '   Loss Function: L(θ) = E[(r + γmax_a\'Q(s\',a\';θ⁻) - Q(s,a;θ))²]',
      '   Experience Replay: Store transitions in buffer, sample mini-batches',
      '   Target Network: θ⁻ updated periodically to stabilize training',
      '   Example: Atari games, complex state spaces',
      '   Visual: Neural network approximating Q-function for high-dimensional states',
      '',
      '🎭 POLICY GRADIENT METHODS:',
      '   REINFORCE: ∇J(θ) = E[∇log π(a|s;θ) Q^π(s,a)]',
      '   Actor-Critic: Actor updates policy, Critic estimates value function',
      '   Advantage: A(s,a) = Q(s,a) - V(s) (reduces variance)',
      '   Example: Continuous control, robotics, complex action spaces',
      '   Visual: Direct policy optimization without value function intermediary',
      '',
      '🚀 PROXIMAL POLICY OPTIMIZATION (PPO):',
      '   Objective: L^CLIP(θ) = E[min(r_t(θ)Â_t, clip(r_t(θ),1-ε,1+ε)Â_t)]',
      '   Ratio: r_t(θ) = π_θ(a_t|s_t)/π_θ_old(a_t|s_t)',
      '   Clipping: Prevents large policy updates, maintains stability',
      '   Example: OpenAI Five (Dota 2), robotics, continuous control',
      '   Visual: Clipped objective function preventing destructive updates',
      '',
      '🎪 ACTOR-CRITIC METHODS:',
      '   Actor: ∇J(θ) = E[∇log π(a|s;θ) A(s,a)]',
      '   Critic: V(s;w) ≈ V^π(s), updated via TD learning',
      '   A3C: Asynchronous Advantage Actor-Critic with multiple workers',
      '   A2C: Synchronous version of A3C',
      '   Example: Complex environments, parallel training',
      '   Visual: Two networks - actor (policy) and critic (value) working together',
      '',
      '🌟 DEEP DETERMINISTIC POLICY GRADIENT (DDPG):',
      '   Deterministic Policy: μ(s;θ^μ) instead of stochastic π(a|s)',
      '   Critic Update: L = E[(r + γQ(s\',μ(s\');θ^Q) - Q(s,a;θ^Q))²]',
      '   Actor Update: ∇J = E[∇_a Q(s,a;θ^Q)|_{a=μ(s)} ∇μ(s;θ^μ)]',
      '   Exploration: Add noise to deterministic policy',
      '   Example: Continuous control tasks, robotic manipulation',
      '   Visual: Deterministic policy mapping states directly to actions',
      '',
      '🎲 MULTI-ARMED BANDITS:',
      '   UCB1: Select action with highest UCB_t(a) = Q̄_t(a) + c√(ln t/N_t(a))',
      '   Thompson Sampling: Sample from posterior distribution of action values',
      '   ε-Greedy: Explore randomly with probability ε',
      '   Example: A/B testing, recommendation systems, online advertising',
      '   Visual: Arms (actions) with unknown reward distributions',
      '',
      '📋 EVALUATION METRICS:',
      '   Cumulative Reward: G_t = Σ_{k=0}^∞ γ^k R_{t+k+1}',
      '   Sample Efficiency: Learning speed (episodes to convergence)',
      '   Policy Performance: Average reward per episode',
      '   Exploration Efficiency: Coverage of state-action space'
    ]
  },
  {
    name: 'Agentic AI vs Generative AI',
    details: [
      '🤖 AGENTIC AI (Goal-Oriented, Action-Taking):',
      '   Definition: AI systems that can take autonomous actions to achieve specific goals',
      '   Core Capability: Decision-making, planning, and executing actions in environments',
      '   Architecture: Agent + Environment + Action Space + Reward Function',
      '   Learning: Through interaction, trial-and-error, reinforcement learning',
      '   Examples: Autonomous vehicles, trading bots, game-playing AI (AlphaGo)',
      '   Visual: Agent interacting with environment, taking actions based on observations',
      '',
      '🎨 GENERATIVE AI (Content Creation):',
      '   Definition: AI systems that create new content (text, images, audio, code)',
      '   Core Capability: Pattern recognition and synthesis from training data',
      '   Architecture: Encoder-Decoder, Transformers, GANs, Diffusion Models',
      '   Learning: Through large datasets, supervised/unsupervised learning',
      '   Examples: ChatGPT, DALL-E, Midjourney, GitHub Copilot, Stable Diffusion',
      '   Visual: Neural network generating new content from learned patterns',
      '',
      '🔍 KEY DIFFERENCES:',
      '',
      '🎯 PURPOSE & GOALS:',
      '   Agentic AI: Optimize outcomes, maximize rewards, achieve objectives',
      '   Generative AI: Create realistic, diverse, high-quality content',
      '',
      '⚙️ INTERACTION MODEL:',
      '   Agentic AI: Interactive, real-time decision making in dynamic environments',
      '   Generative AI: One-shot or iterative content generation from prompts',
      '',
      '📊 TRAINING APPROACH:',
      '   Agentic AI: Reinforcement Learning, Online Learning, Trial-and-Error',
      '   Generative AI: Supervised Learning, Self-Supervised, Large-Scale Pretraining',
      '',
      '🎮 ENVIRONMENT:',
      '   Agentic AI: Dynamic, reactive environments (games, real world, simulations)',
      '   Generative AI: Static datasets, text corpora, image collections',
      '',
      '📈 EVALUATION METRICS:',
      '   Agentic AI: Reward/utility maximization, success rate, efficiency',
      '   Generative AI: Quality, diversity, coherence, human preference',
      '',
      '🔄 FEEDBACK LOOP:',
      '   Agentic AI: Immediate environment feedback, reward signals',
      '   Generative AI: Human feedback, preference learning, RLHF',
      '',
      '⚡ REAL-TIME REQUIREMENTS:',
      '   Agentic AI: Often requires real-time decision making',
      '   Generative AI: Can operate with longer inference times for quality',
      '',
      '🎲 EXPLORATION vs EXPLOITATION:',
      '   Agentic AI: Critical balance between exploring new strategies and exploiting known good ones',
      '   Generative AI: Exploration through randomness/sampling for diversity',
      '',
      '🚀 EMERGING HYBRID APPROACHES:',
      '   Agent + LLM: Language agents that can reason and take actions',
      '   Generative Agents: AI agents that can generate plans and content',
      '   Examples: ChatGPT with plugins, AutoGPT, LangChain agents',
      '   Visual: Integration of both paradigms for comprehensive AI systems',
      '',
      '📋 PRACTICAL APPLICATIONS:',
      '   Agentic AI: Robotics, autonomous systems, algorithmic trading, game AI',
      '   Generative AI: Content creation, code generation, art, writing assistance',
      '   Hybrid: AI assistants, creative collaborators, intelligent automation'
    ]
  },
  {
    name: 'Entropy vs Gini Index',
    details: [
      '🌳 DECISION TREE SPLIT CRITERIA COMPARISON:',
      '   Purpose: Both measure impurity/uncertainty in data splits for decision trees',
      '   Goal: Find optimal splits that maximize information gain and purity',
      '',
      '📊 ENTROPY (Information Theory Based):',
      '   Formula: H(S) = -Σᵢ pᵢ × log₂(pᵢ)',
      '   Range: 0 (pure) to log₂(n) where n = number of classes',
      '   Binary Classification: H(S) = -p₁log₂(p₁) - p₂log₂(p₂)',
      '   Maximum: log₂(2) = 1 for binary, occurs when p₁ = p₂ = 0.5',
      '   Interpretation: Average number of bits needed to encode class information',
      '   Example: For [50% Class A, 50% Class B]: H = -0.5×log₂(0.5) - 0.5×log₂(0.5) = 1',
      '',
      '🎯 GINI INDEX (Probability Based):',
      '   Formula: Gini(S) = 1 - Σᵢ pᵢ²',
      '   Range: 0 (pure) to 0.5 (maximum impurity for binary)',
      '   Binary Classification: Gini(S) = 1 - p₁² - p₂²',
      '   Maximum: 0.5 for binary, occurs when p₁ = p₂ = 0.5',
      '   Interpretation: Probability of misclassifying a randomly chosen element',
      '   Example: For [50% Class A, 50% Class B]: Gini = 1 - 0.5² - 0.5² = 0.5',
      '',
      '🔍 KEY DIFFERENCES:',
      '',
      '📈 MATHEMATICAL PROPERTIES:',
      '   Entropy: Logarithmic function, more sensitive to probability changes',
      '   Gini: Quadratic function, computationally simpler (no logarithms)',
      '   Entropy: Higher penalty for very uneven splits',
      '   Gini: More balanced penalty across probability ranges',
      '',
      '⚡ COMPUTATIONAL COMPLEXITY:',
      '   Entropy: Requires logarithm calculation (more expensive)',
      '   Gini: Simple arithmetic operations (faster)',
      '   Performance: Gini typically 2-3x faster to compute',
      '',
      '📊 SENSITIVITY ANALYSIS:',
      '   Entropy: More sensitive to small probability changes near 0 or 1',
      '   Gini: More stable, less sensitive to extreme probabilities',
      '   Split Selection: Entropy tends to favor more balanced splits',
      '   Practical Impact: Usually produce similar tree structures',
      '',
      '🎲 PRACTICAL EXAMPLES:',
      '',
      '   Dataset: [80% Class A, 20% Class B]',
      '   Entropy: H = -0.8×log₂(0.8) - 0.2×log₂(0.2) = 0.722',
      '   Gini: G = 1 - 0.8² - 0.2² = 1 - 0.64 - 0.04 = 0.32',
      '',
      '   Dataset: [90% Class A, 10% Class B]',
      '   Entropy: H = -0.9×log₂(0.9) - 0.1×log₂(0.1) = 0.469',
      '   Gini: G = 1 - 0.9² - 0.1² = 1 - 0.81 - 0.01 = 0.18',
      '',
      '🌟 INFORMATION GAIN CALCULATION:',
      '   Information Gain: IG = H(parent) - Σ(|child|/|parent|) × H(child)',
      '   Gini Gain: GG = Gini(parent) - Σ(|child|/|parent|) × Gini(child)',
      '   Both aim to maximize gain (reduce impurity after split)',
      '',
      '🚀 ALGORITHM PREFERENCES:',
      '   C4.5/C5.0: Uses Entropy (information gain ratio)',
      '   CART: Uses Gini Index by default',
      '   Random Forest: Often uses Gini for speed',
      '   scikit-learn: Gini default, Entropy available',
      '',
      '📋 DECISION GUIDELINES:',
      '   Use Entropy: When interpretability matters, theoretical analysis',
      '   Use Gini: When speed is critical, large datasets, production systems',
      '   Performance: Both typically yield similar accuracy',
      '   Default Choice: Gini for most practical applications'
    ]
  },
  {
    name: 'Linear Regression Deep Dive',
    details: [
      '📈 DEFINITION & PURPOSE:',
      '   Goal: Find the best linear relationship between input features (X) and target (y)',
      '   Assumption: Linear relationship exists between variables',
      '   Output: Continuous numerical predictions',
      '',
      '🔢 MATHEMATICAL FOUNDATION:',
      '',
      '📊 SIMPLE LINEAR REGRESSION (1 Feature):',
      '   Model: y = β₀ + β₁x + ε',
      '   β₀: y-intercept (bias term)',
      '   β₁: slope (weight/coefficient)',
      '   ε: error term (noise)',
      '   Prediction: ŷ = β₀ + β₁x',
      '',
      '🎯 MULTIPLE LINEAR REGRESSION (n Features):',
      '   Model: y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε',
      '   Matrix Form: y = Xβ + ε',
      '   X: [1, x₁, x₂, ..., xₙ] (design matrix with bias column)',
      '   β: [β₀, β₁, β₂, ..., βₙ]ᵀ (parameter vector)',
      '',
      '💰 COST FUNCTION (Mean Squared Error):',
      '   MSE = (1/2m) Σᵢ₌₁ᵐ (hθ(x⁽ⁱ⁾) - y⁽ⁱ⁾)²',
      '   hθ(x⁽ⁱ⁾) = θ₀ + θ₁x₁⁽ⁱ⁾ + ... + θₙxₙ⁽ⁱ⁾',
      '   m: number of training examples',
      '   Goal: minimize J(θ) = MSE',
      '',
      '🧮 ANALYTICAL SOLUTION (Normal Equation):',
      '   θ = (XᵀX)⁻¹Xᵀy',
      '   Derivation: ∇J(θ) = 0',
      '   ∂J/∂θ = XᵀXθ - Xᵀy = 0',
      '   Pros: Exact solution, no learning rate needed',
      '   Cons: O(n³) complexity, requires matrix inversion',
      '',
      '⚡ GRADIENT DESCENT APPROACH:',
      '',
      '📉 BATCH GRADIENT DESCENT:',
      '   Update Rule: θⱼ := θⱼ - α(∂J/∂θⱼ)',
      '   Partial Derivative: ∂J/∂θⱼ = (1/m) Σᵢ₌₁ᵐ (hθ(x⁽ⁱ⁾) - y⁽ⁱ⁾)xⱼ⁽ⁱ⁾',
      '   α: learning rate (typically 0.01 to 0.3)',
      '   Convergence: When ||∇J(θ)|| < tolerance',
      '',
      '🔄 STOCHASTIC GRADIENT DESCENT (SGD):',
      '   Update per example: θⱼ := θⱼ - α(hθ(x⁽ⁱ⁾) - y⁽ⁱ⁾)xⱼ⁽ⁱ⁾',
      '   Faster updates, more noisy convergence',
      '   Good for large datasets (m > 10,000)',
      '',
      '🎨 VISUAL REPRESENTATION:',
      '   Simple Linear: Straight line y = mx + b on 2D plot',
      '   Multiple Linear: Hyperplane in n-dimensional space',
      '   Cost Function: Convex bowl shape (single global minimum)',
      '   Gradient Descent: Ball rolling down the cost surface',
      '',
      '🏠 PRACTICAL EXAMPLE - House Price Prediction:',
      '',
      '   Features: Size (sq ft), Bedrooms, Age, Location Score',
      '   Model: Price = β₀ + β₁×Size + β₂×Bedrooms + β₃×Age + β₄×Location',
      '',
      '   Sample Data:',
      '   House 1: Size=1500, Beds=3, Age=10, Loc=8 → Price=$300K',
      '   House 2: Size=2000, Beds=4, Age=5, Loc=9 → Price=$450K',
      '',
      '   After Training:',
      '   Price = 50000 + 150×Size + 10000×Beds - 2000×Age + 5000×Loc',
      '   Interpretation: Each sq ft adds $150, each bedroom adds $10K',
      '',
      '📊 ASSUMPTIONS & REQUIREMENTS:',
      '   1. Linearity: Relationship between X and y is linear',
      '   2. Independence: Observations are independent',
      '   3. Homoscedasticity: Constant variance of residuals',
      '   4. Normality: Residuals are normally distributed',
      '   5. No Multicollinearity: Features not highly correlated',
      '',
      '⚠️ COMMON PROBLEMS & SOLUTIONS:',
      '   Overfitting: Use regularization (Ridge/Lasso)',
      '   Multicollinearity: Remove correlated features, use PCA',
      '   Non-linearity: Feature engineering, polynomial features',
      '   Outliers: Robust regression, outlier detection',
      '',
      '🔧 FEATURE ENGINEERING:',
      '   Polynomial Features: x₁, x₂, x₁², x₂², x₁x₂',
      '   Interaction Terms: x₁ × x₂, x₁ × x₃',
      '   Log Transform: log(x) for exponential relationships',
      '   Normalization: (x - μ)/σ for different scales',
      '',
      '📈 EVALUATION METRICS:',
      '   MSE = (1/n) Σ(yᵢ - ŷᵢ)²',
      '   RMSE = √MSE (same units as target)',
      '   MAE = (1/n) Σ|yᵢ - ŷᵢ| (robust to outliers)',
      '   R² = 1 - (SS_res/SS_tot) (proportion of variance explained)',
      '',
      '💻 IMPLEMENTATION STEPS:',
      '   1. Data Preprocessing: Handle missing values, normalize',
      '   2. Feature Selection: Choose relevant features',
      '   3. Train-Test Split: Typically 80-20 or 70-30',
      '   4. Model Training: Fit using Normal Equation or GD',
      '   5. Evaluation: Calculate metrics on test set',
      '   6. Validation: Cross-validation for robustness'
    ]
  },
  {
    name: 'Logistic Regression Deep Dive',
    details: [
      '🎯 DEFINITION & PURPOSE:',
      '   Goal: Predict probability of binary/categorical outcomes (classification)',
      '   Output: Probability between 0 and 1',
      '   Decision Boundary: Linear separation in feature space',
      '   Applications: Email spam, medical diagnosis, marketing response',
      '',
      '📊 FUNDAMENTAL CONCEPT:',
      '   Problem: Linear regression outputs unbounded values (-∞ to +∞)',
      '   Solution: Map linear output to probability using sigmoid function',
      '   Advantage: Probabilistic interpretation of predictions',
      '',
      '🔢 SIGMOID FUNCTION (LOGISTIC FUNCTION):',
      '   Formula: σ(z) = 1/(1 + e^(-z))',
      '   Input: z = θ₀ + θ₁x₁ + θ₂x₂ + ... + θₙxₙ',
      '   Output Range: (0, 1)',
      '   Properties: S-shaped curve, differentiable, monotonic',
      '',
      '📈 SIGMOID CURVE CHARACTERISTICS:',
      '   At z = 0: σ(0) = 1/(1 + e⁰) = 1/2 = 0.5',
      '   As z → +∞: σ(z) → 1',
      '   As z → -∞: σ(z) → 0',
      '   Derivative: σ\'(z) = σ(z)(1 - σ(z))',
      '   Maximum slope at z = 0',
      '',
      '🎯 LOGISTIC REGRESSION MODEL:',
      '   Hypothesis: h_θ(x) = σ(θᵀx) = 1/(1 + e^(-θᵀx))',
      '   Prediction: ŷ = 1 if h_θ(x) ≥ 0.5, else 0',
      '   Decision Boundary: θᵀx = 0 (where h_θ(x) = 0.5)',
      '',
      '📊 PROBABILITY INTERPRETATION:',
      '   P(y=1|x;θ) = h_θ(x) = sigmoid(θᵀx)',
      '   P(y=0|x;θ) = 1 - h_θ(x)',
      '   Odds Ratio: P(y=1)/P(y=0) = e^(θᵀx)',
      '   Log-Odds (Logit): ln(P(y=1)/P(y=0)) = θᵀx',
      '',
      '💰 COST FUNCTION (LOG-LIKELIHOOD):',
      '   Cannot use MSE (non-convex for sigmoid)',
      '   Use Maximum Likelihood Estimation (MLE)',
      '   Likelihood: L(θ) = ∏ᵢ₌₁ᵐ P(y⁽ⁱ⁾|x⁽ⁱ⁾;θ)',
      '   Log-Likelihood: ℓ(θ) = Σᵢ₌₁ᵐ [y⁽ⁱ⁾log(h_θ(x⁽ⁱ⁾)) + (1-y⁽ⁱ⁾)log(1-h_θ(x⁽ⁱ⁾))]',
      '',
      '🎯 COST FUNCTION FORMULA:',
      '   J(θ) = -(1/m) Σᵢ₌₁ᵐ [y⁽ⁱ⁾log(h_θ(x⁽ⁱ⁾)) + (1-y⁽ⁱ⁾)log(1-h_θ(x⁽ⁱ⁾))]',
      '   Individual Cost: cost(h_θ(x),y) = -ylog(h_θ(x)) - (1-y)log(1-h_θ(x))',
      '   Properties: Convex, differentiable, penalizes wrong predictions heavily',
      '',
      '⚡ GRADIENT DESCENT:',
      '   Partial Derivative: ∂J/∂θⱼ = (1/m) Σᵢ₌₁ᵐ (h_θ(x⁽ⁱ⁾) - y⁽ⁱ⁾)xⱼ⁽ⁱ⁾',
      '   Update Rule: θⱼ := θⱼ - α(∂J/∂θⱼ)',
      '   Note: Same form as linear regression but h_θ(x) is sigmoid!',
      '   Learning Rate: Typically 0.01 to 1.0',
      '',
      '🧮 DERIVATION OF GRADIENT:',
      '   ∂σ/∂z = σ(z)(1-σ(z))',
      '   ∂J/∂θⱼ = -(1/m) Σᵢ [y⁽ⁱ⁾/h_θ(x⁽ⁱ⁾) - (1-y⁽ⁱ⁾)/(1-h_θ(x⁽ⁱ⁾))] × ∂h_θ/∂θⱼ',
      '   Simplifies to: (1/m) Σᵢ (h_θ(x⁽ⁱ⁾) - y⁽ⁱ⁾)xⱼ⁽ⁱ⁾',
      '',
      '🎨 VISUAL REPRESENTATION:',
      '   1D Feature: S-curve separating two classes',
      '   2D Features: Linear decision boundary line',
      '   nD Features: Hyperplane in n-dimensional space',
      '   Cost Surface: Convex bowl (single global minimum)',
      '   Probability Contours: Smooth gradients from 0 to 1',
      '',
      '📧 PRACTICAL EXAMPLE - Email Spam Detection:',
      '',
      '   Features: Word count ("free"), exclamation marks, caps ratio',
      '   Model: P(spam) = σ(θ₀ + θ₁×"free_count" + θ₂×exclamations + θ₃×caps_ratio)',
      '',
      '   Sample Training:',
      '   Email 1: free=5, !=3, caps=0.8 → Spam (y=1)',
      '   Email 2: free=0, !=1, caps=0.1 → Not Spam (y=0)',
      '',
      '   After Training:',
      '   θ = [-2.0, 1.5, 0.8, 2.0]',
      '   New Email: free=3, !=2, caps=0.6',
      '   z = -2.0 + 1.5×3 + 0.8×2 + 2.0×0.6 = 4.3',
      '   P(spam) = 1/(1 + e^(-4.3)) = 0.986 → 98.6% spam probability',
      '',
      '🔄 MULTICLASS CLASSIFICATION:',
      '   One-vs-Rest (OvR): Train n binary classifiers',
      '   One-vs-One (OvO): Train n(n-1)/2 classifiers',
      '   Softmax Regression: Direct multiclass extension',
      '   Softmax: P(y=k|x) = e^(θₖᵀx) / Σⱼe^(θⱼᵀx)',
      '',
      '📊 ASSUMPTIONS & REQUIREMENTS:',
      '   1. Linear relationship between logit and features',
      '   2. Independence of observations',
      '   3. No severe multicollinearity',
      '   4. Large sample size (at least 10 events per parameter)',
      '   5. No extreme outliers',
      '',
      '⚠️ COMMON ISSUES & SOLUTIONS:',
      '   Perfect Separation: Use regularization (L1/L2)',
      '   Multicollinearity: Remove correlated features',
      '   Outliers: Robust scaling, outlier detection',
      '   Imbalanced Data: SMOTE, class weights, threshold tuning',
      '',
      '🔧 REGULARIZATION:',
      '   L1 (Lasso): J(θ) + λΣ|θⱼ| (feature selection)',
      '   L2 (Ridge): J(θ) + λΣθⱼ² (prevents overfitting)',
      '   Elastic Net: Combination of L1 and L2',
      '',
      '📈 EVALUATION METRICS:',
      '   Accuracy = (TP + TN)/(TP + TN + FP + FN)',
      '   Precision = TP/(TP + FP)',
      '   Recall = TP/(TP + FN)',
      '   F1-Score = 2×(Precision×Recall)/(Precision+Recall)',
      '   AUC-ROC: Area under ROC curve',
      '   Log-Loss: -(1/n)Σ[yᵢlog(pᵢ) + (1-yᵢ)log(1-pᵢ)]',
      '',
      '🎯 DECISION THRESHOLD TUNING:',
      '   Default: 0.5 threshold',
      '   High Precision: Increase threshold (fewer false positives)',
      '   High Recall: Decrease threshold (fewer false negatives)',
      '   ROC Curve: Plot TPR vs FPR for all thresholds',
      '',
      '💻 IMPLEMENTATION STEPS:',
      '   1. Data Preprocessing: Handle missing values, encode categoricals',
      '   2. Feature Scaling: Standardize for better convergence',
      '   3. Train-Test Split: Stratified split for balanced classes',
      '   4. Model Training: Gradient descent or Newton-Raphson',
      '   5. Threshold Tuning: Optimize based on business requirements',
      '   6. Evaluation: Multiple metrics, cross-validation'
    ]
  },
  {
    name: '🎯 Softmax Function Deep Dive',
    details: [
      '🧮 MATHEMATICAL FOUNDATION:',
      '   Formula: σ(z_i) = e^(z_i) / Σ(j=1 to K) e^(z_j)',
      '   Where: z_i = input for class i, K = total classes',
      '   Output: Probability distribution where Σ σ(z_i) = 1',
      '   Properties: All values ∈ [0,1], differentiable, smooth',
      '',
      '🎛️ TEMPERATURE PARAMETER:',
      '   Modified Formula: σ(z_i) = e^(z_i/T) / Σ(j=1 to K) e^(z_j/T)',
      '   T → 0: Becomes argmax (one-hot distribution)',
      '   T → ∞: Becomes uniform distribution (1/K for all classes)',
      '   T = 1: Standard softmax',
      '   Use Cases: Controlling confidence, knowledge distillation',
      '',
      '📊 PRACTICAL EXAMPLE - IMAGE CLASSIFICATION:',
      '   Raw Model Outputs (logits): [Cat: 2.0, Dog: 1.0, Bird: 0.1]',
      '   Exponentials: [e^2.0 = 7.39, e^1.0 = 2.72, e^0.1 = 1.11]',
      '   Sum: 7.39 + 2.72 + 1.11 = 11.22',
      '   Probabilities: [Cat: 65.9%, Dog: 24.2%, Bird: 9.9%]',
      '   Interpretation: Model is most confident about "Cat"',
      '',
      '🔥 KEY PROPERTIES:',
      '   1. Probability Distribution: All outputs sum to 1',
      '   2. Exponential Amplification: Emphasizes maximum values',
      '   3. Differentiable: Smooth gradients for backpropagation',
      '   4. Monotonic: Preserves relative ordering of inputs',
      '   5. Scale Invariant: Adding constant to all inputs unchanged output',
      '',
      '🎯 CROSS-ENTROPY LOSS CONNECTION:',
      '   Loss Function: L = -Σ(i=1 to K) y_i × log(σ(z_i))',
      '   Gradient: ∂L/∂z_i = σ(z_i) - y_i',
      '   Beautiful Property: Gradient = predicted_prob - true_prob',
      '   Interpretation: Directly optimizes probability predictions',
      '',
      '⚠️ NUMERICAL STABILITY:',
      '   Problem: Large values cause overflow (e^1000 = ∞)',
      '   Solution: Subtract maximum value before computation',
      '   Stable Formula: z\' = z - max(z), then apply softmax to z\'',
      '   Mathematical Equivalence: Result unchanged, but prevents overflow',
      '   Implementation: Always use this trick in production code',
      '',
      '🚀 APPLICATIONS:',
      '   • Multi-class Classification: Final layer of neural networks',
      '   • Attention Mechanisms: Transformer models, seq2seq',
      '   • Reinforcement Learning: Action probability distributions',
      '   • Natural Language Processing: Next word prediction',
      '   • Computer Vision: Object detection, semantic segmentation',
      '   • Recommendation Systems: Item probability scoring',
      '',
      '🔄 SOFTMAX vs SIGMOID:',
      '   Sigmoid: Binary classification, independent probabilities',
      '   Softmax: Multi-class classification, mutually exclusive probabilities',
      '   Sigmoid: σ(z) = 1/(1 + e^(-z)), output ∈ [0,1]',
      '   Softmax: Generalizes sigmoid to multiple classes',
      '   Use Case: Sigmoid for multi-label, Softmax for multi-class',
      '',
      '💻 IMPLEMENTATION EXAMPLE:',
      '   def softmax(z):',
      '       # Numerical stability',
      '       z_shifted = z - np.max(z)',
      '       exp_z = np.exp(z_shifted)',
      '       return exp_z / np.sum(exp_z)',
      '   ',
      '   # Usage in neural network',
      '   logits = model(x)  # Raw outputs',
      '   probabilities = softmax(logits)  # Convert to probabilities',
      '   prediction = np.argmax(probabilities)  # Get predicted class'
    ]
  },
  {
    name: '🛡️ Support Vector Machine (SVM) Deep Dive',
    details: [
      '🎯 DEFINITION & CORE CONCEPT:',
      '   Goal: Find optimal hyperplane that separates classes with maximum margin',
      '   Key Idea: Maximize distance between decision boundary and closest points',
      '   Support Vectors: Data points closest to the hyperplane (critical for model)',
      '   Applications: Text classification, image recognition, bioinformatics',
      '',
      '📐 MATHEMATICAL FOUNDATION:',
      '',
      '🔍 LINEAR SVM (SEPARABLE CASE):',
      '   Decision Function: f(x) = sign(w·x + b)',
      '   Hyperplane Equation: w·x + b = 0',
      '   Where: w = weight vector (normal to hyperplane)',
      '         b = bias term (shifts hyperplane)',
      '         x = input feature vector',
      '',
      '📏 MARGIN CALCULATION:',
      '   Geometric Margin: γ = |w·x + b|/||w||',
      '   Functional Margin: γ̃ = y(w·x + b)',
      '   Maximum Margin: M = 2/||w|| (distance between support vectors)',
      '   Constraint: yᵢ(w·xᵢ + b) ≥ 1 for all training points',
      '',
      '🎯 OPTIMIZATION PROBLEM (PRIMAL FORM):',
      '   Objective: minimize (1/2)||w||² subject to yᵢ(w·xᵢ + b) ≥ 1',
      '   Quadratic Programming: Convex optimization problem',
      '   Lagrangian: L = (1/2)||w||² - Σᵢαᵢ[yᵢ(w·xᵢ + b) - 1]',
      '   KKT Conditions: αᵢ ≥ 0, αᵢ[yᵢ(w·xᵢ + b) - 1] = 0',
      '',
      '🔄 DUAL FORMULATION:',
      '   Objective: maximize Σᵢαᵢ - (1/2)ΣᵢΣⱼαᵢαⱼyᵢyⱼ(xᵢ·xⱼ)',
      '   Subject to: Σᵢαᵢyᵢ = 0, αᵢ ≥ 0',
      '   Solution: w = Σᵢαᵢyᵢxᵢ (only support vectors have αᵢ > 0)',
      '   Decision: f(x) = sign(Σᵢαᵢyᵢ(xᵢ·x) + b)',
      '',
      '🎨 VISUAL REPRESENTATION:',
      '   2D Case: Line separating two classes with maximum margin',
      '   3D Case: Plane dividing space into two regions',
      '   Support Vectors: Points exactly on the margin boundaries',
      '   Margin: "Street" between classes - widest possible separation',
      '   Non-Support Vectors: Can be moved without affecting decision boundary',
      '',
      '🌟 SOFT MARGIN SVM (NON-SEPARABLE CASE):',
      '   Problem: Real data often not linearly separable',
      '   Solution: Allow some misclassification with penalty',
      '   Slack Variables: ξᵢ ≥ 0 for constraint violations',
      '   Modified Constraint: yᵢ(w·xᵢ + b) ≥ 1 - ξᵢ',
      '',
      '⚖️ C-PARAMETER REGULARIZATION:',
      '   Objective: minimize (1/2)||w||² + C·Σᵢξᵢ',
      '   C → ∞: Hard margin (no misclassification allowed)',
      '   C → 0: Very soft margin (focus on large margin)',
      '   Trade-off: Margin width vs classification accuracy',
      '   Typical values: C ∈ [0.1, 100]',
      '',
      '🔮 KERNEL TRICK (NON-LINEAR SVM):',
      '   Problem: Linear boundaries insufficient for complex data',
      '   Solution: Map data to higher-dimensional space',
      '   Kernel Function: K(xᵢ, xⱼ) = φ(xᵢ)·φ(xⱼ)',
      '   Advantage: No explicit computation of φ(x)',
      '',
      '🧮 POPULAR KERNEL FUNCTIONS:',
      '',
      '   📈 LINEAR KERNEL:',
      '   K(xᵢ, xⱼ) = xᵢ·xⱼ',
      '   Use: Linearly separable data, text classification',
      '',
      '   🌀 POLYNOMIAL KERNEL:',
      '   K(xᵢ, xⱼ) = (γxᵢ·xⱼ + r)ᵈ',
      '   Parameters: d=degree, γ=scaling, r=offset',
      '   Use: Moderate non-linearity, image processing',
      '',
      '   🎯 RBF (RADIAL BASIS FUNCTION) KERNEL:',
      '   K(xᵢ, xⱼ) = exp(-γ||xᵢ - xⱼ||²)',
      '   Parameter: γ controls "influence radius"',
      '   High γ: Tight fit (overfitting risk)',
      '   Low γ: Smooth boundary (underfitting risk)',
      '   Use: Most popular, handles complex non-linear patterns',
      '',
      '   🌊 SIGMOID KERNEL:',
      '   K(xᵢ, xⱼ) = tanh(γxᵢ·xⱼ + r)',
      '   Use: Neural network-like behavior',
      '',
      '🔍 PRACTICAL EXAMPLE - EMAIL SPAM CLASSIFICATION:',
      '',
      '   Features: [word_count("free"), exclamation_marks, caps_ratio]',
      '   Training Data:',
      '   Email 1: [5, 3, 0.8] → Spam (y=+1)',
      '   Email 2: [0, 1, 0.1] → Ham (y=-1)',
      '   Email 3: [2, 0, 0.2] → Ham (y=-1)',
      '',
      '   Linear SVM Result:',
      '   Hyperplane: 0.6×word_count + 0.4×exclamations + 0.8×caps_ratio - 1.2 = 0',
      '   Support Vectors: Emails exactly on margin boundaries',
      '   New Email: [3, 2, 0.5] → f(x) = sign(0.6×3 + 0.4×2 + 0.8×0.5 - 1.2) = +1 (Spam)',
      '',
      '🎭 MULTICLASS SVM:',
      '   One-vs-One (OvO): Train C(C-1)/2 binary classifiers',
      '   One-vs-Rest (OvR): Train C binary classifiers',
      '   Decision: Majority voting or highest confidence score',
      '   ECOC: Error-Correcting Output Codes for robustness',
      '',
      '📊 ADVANTAGES:',
      '   ✅ Effective in high-dimensional spaces',
      '   ✅ Memory efficient (uses subset of training points)',
      '   ✅ Versatile (different kernels for different problems)',
      '   ✅ Works well with small datasets',
      '   ✅ Strong theoretical foundation',
      '',
      '⚠️ DISADVANTAGES:',
      '   ❌ No probabilistic output (unlike logistic regression)',
      '   ❌ Sensitive to feature scaling',
      '   ❌ Slow on large datasets (O(n³) training complexity)',
      '   ❌ Choice of kernel and parameters crucial',
      '   ❌ No direct interpretation of feature importance',
      '',
      '🔧 HYPERPARAMETER TUNING:',
      '   C Parameter: Controls regularization strength',
      '   Gamma (RBF): Controls kernel width/influence',
      '   Kernel Selection: Try linear first, then RBF',
      '   Grid Search: Systematic parameter exploration',
      '   Cross-Validation: Prevent overfitting during tuning',
      '',
      '📈 EVALUATION METRICS:',
      '   Accuracy: (TP + TN)/(TP + TN + FP + FN)',
      '   Precision/Recall: For imbalanced datasets',
      '   F1-Score: Harmonic mean of precision and recall',
      '   Support Vector Count: Indicator of model complexity',
      '   Margin Width: 2/||w|| (larger is better for generalization)',
      '',
      '🔬 ADVANCED CONCEPTS:',
      '   ν-SVM: Alternative formulation with ν parameter',
      '   One-Class SVM: Novelty/anomaly detection',
      '   SVR: Support Vector Regression for continuous targets',
      '   Sequential Minimal Optimization (SMO): Efficient training algorithm',
      '',
      '💻 IMPLEMENTATION PIPELINE:',
      '   1. Data Preprocessing: Handle missing values, encode categories',
      '   2. Feature Scaling: StandardScaler or MinMaxScaler (CRITICAL!)',
      '   3. Kernel Selection: Start with RBF, try linear for text',
      '   4. Hyperparameter Tuning: Grid search with CV',
      '   5. Model Training: Fit on training set',
      '   6. Evaluation: Test on holdout set, analyze support vectors',
      '',
      '🎯 DECISION BOUNDARY VISUALIZATION:',
      '   Linear SVM: Straight line/plane separating classes',
      '   RBF SVM: Curved, complex boundaries following data shape',
      '   Support Vectors: Highlighted points defining the boundary',
      '   Margin: Parallel lines/planes showing separation width',
      '   Misclassified Points: Inside margin or wrong side of boundary'
    ]
  },
  {
    name: '⛰️ Gradient Descent Deep Dive',
    details: [
      '🎯 DEFINITION & CORE CONCEPT:',
      '   Goal: Find minimum of cost function by iteratively moving in steepest descent direction',
      '   Key Idea: Use negative gradient to guide parameter updates',
      '   Analogy: Rolling ball down hill to find lowest point',
      '   Applications: Training neural networks, linear/logistic regression, optimization',
      '',
      '📐 MATHEMATICAL FOUNDATION:',
      '',
      '🔍 BASIC GRADIENT DESCENT:',
      '   Update Rule: θ := θ - α∇J(θ)',
      '   Where: θ = parameters, α = learning rate, ∇J(θ) = gradient',
      '   Gradient: ∇J(θ) = [∂J/∂θ₁, ∂J/∂θ₂, ..., ∂J/∂θₙ]ᵀ',
      '   Intuition: Move opposite to gradient direction (steepest ascent)',
      '',
      '📏 LEARNING RATE (α):',
      '   Critical Hyperparameter: Controls step size',
      '   Too Large: Overshooting, oscillation, divergence',
      '   Too Small: Slow convergence, many iterations needed',
      '   Typical Values: 0.001, 0.01, 0.1, 0.3',
      '   Adaptive Methods: Automatically adjust learning rate',
      '',
      '🎯 CONVERGENCE CONDITIONS:',
      '   Gradient Norm: ||∇J(θ)|| < ε (typically ε = 10⁻⁶)',
      '   Parameter Change: ||θᵗ⁺¹ - θᵗ|| < ε',
      '   Cost Change: |J(θᵗ⁺¹) - J(θᵗ)| < ε',
      '   Maximum Iterations: Prevent infinite loops',
      '',
      '🔄 GRADIENT DESCENT VARIANTS:',
      '',
      '📊 1. BATCH GRADIENT DESCENT (BGD):',
      '   Formula: θ := θ - α(1/m)Σᵢ₌₁ᵐ ∇J(θ; xⁱ, yⁱ)',
      '   Uses: Entire dataset for each update',
      '   Pros: Stable convergence, exact gradient',
      '   Cons: Slow for large datasets, memory intensive',
      '   Best For: Small to medium datasets (m < 10,000)',
      '',
      '⚡ 2. STOCHASTIC GRADIENT DESCENT (SGD):',
      '   Formula: θ := θ - α∇J(θ; xⁱ, yⁱ)',
      '   Uses: Single example for each update',
      '   Pros: Fast updates, can escape local minima',
      '   Cons: Noisy convergence, fluctuating cost',
      '   Best For: Large datasets, online learning',
      '',
      '🎯 3. MINI-BATCH GRADIENT DESCENT:',
      '   Formula: θ := θ - α(1/b)Σᵢ∈batch ∇J(θ; xⁱ, yⁱ)',
      '   Uses: Small batch (typically 32, 64, 128, 256)',
      '   Pros: Balance between BGD and SGD, vectorization',
      '   Cons: Additional hyperparameter (batch size)',
      '   Best For: Most practical applications',
      '',
      '🚀 ADVANCED OPTIMIZATION ALGORITHMS:',
      '',
      '📈 4. MOMENTUM:',
      '   Velocity: vₜ = βvₜ₋₁ + α∇J(θₜ)',
      '   Update: θₜ₊₁ = θₜ - vₜ',
      '   Parameter: β ∈ [0.8, 0.99] (momentum coefficient)',
      '   Intuition: Accumulate velocity, overcome small gradients',
      '   Benefits: Faster convergence, reduced oscillation',
      '',
      '🏃 5. NESTEROV ACCELERATED GRADIENT (NAG):',
      '   Look-ahead: θ̃ = θₜ - βvₜ₋₁',
      '   Gradient: ∇J(θ̃)',
      '   Velocity: vₜ = βvₜ₋₁ + α∇J(θ̃)',
      '   Update: θₜ₊₁ = θₜ - vₜ',
      '   Advantage: "Look before you leap" - anticipatory updates',
      '',
      '🎛️ 6. ADAGRAD (ADAPTIVE GRADIENT):',
      '   Accumulator: Gₜ = Gₜ₋₁ + (∇J(θₜ))²',
      '   Update: θₜ₊₁ = θₜ - (α/√(Gₜ + ε))∇J(θₜ)',
      '   Features: Per-parameter learning rates',
      '   Problem: Learning rate decays too aggressively',
      '   Good For: Sparse features, different scales',
      '',
      '🔄 7. RMSPROP:',
      '   Moving Average: vₜ = βvₜ₋₁ + (1-β)(∇J(θₜ))²',
      '   Update: θₜ₊₁ = θₜ - (α/√(vₜ + ε))∇J(θₜ)',
      '   Parameter: β ≈ 0.9 (decay rate)',
      '   Fix: Resolves Adagrad\'s learning rate decay issue',
      '   Creator: Geoffrey Hinton (unpublished)',
      '',
      '🧠 8. ADAM (ADAPTIVE MOMENT ESTIMATION):',
      '   First Moment: m̂ₜ = mₜ/(1-β₁ᵗ), mₜ = β₁mₜ₋₁ + (1-β₁)∇J(θₜ)',
      '   Second Moment: v̂ₜ = vₜ/(1-β₂ᵗ), vₜ = β₂vₜ₋₁ + (1-β₂)(∇J(θₜ))²',
      '   Update: θₜ₊₁ = θₜ - α(m̂ₜ/√(v̂ₜ + ε))',
      '   Parameters: β₁=0.9, β₂=0.999, α=0.001, ε=10⁻⁸',
      '   Features: Combines momentum + RMSprop, bias correction',
      '',
      '🔧 9. ADAMW (ADAM WITH WEIGHT DECAY):',
      '   Decoupled Weight Decay: θₜ₊₁ = θₜ - α(m̂ₜ/√(v̂ₜ + ε) + λθₜ)',
      '   Parameter: λ = weight decay coefficient',
      '   Improvement: Better regularization than L2 in Adam',
      '   Popular: State-of-the-art for transformer training',
      '',
      '⚡ 10. ADADELTA:',
      '   Running Average: E[g²]ₜ = ρE[g²]ₜ₋₁ + (1-ρ)gₜ²',
      '   Parameter Update: Δθₜ = -(√(E[Δθ²]ₜ₋₁ + ε)/√(E[g²]ₜ + ε))gₜ',
      '   No Learning Rate: Self-adaptive, eliminates α hyperparameter',
      '   Robust: Less sensitive to hyperparameters',
      '',
      '📊 PRACTICAL EXAMPLE - LINEAR REGRESSION:',
      '',
      '   Cost Function: J(θ) = (1/2m)Σᵢ(hθ(xⁱ) - yⁱ)²',
      '   Gradient: ∇J(θⱼ) = (1/m)Σᵢ(hθ(xⁱ) - yⁱ)xⱼⁱ',
      '',
      '   Initial: θ₀ = 0, θ₁ = 0, α = 0.01',
      '   Data: (x=1,y=2), (x=2,y=4), (x=3,y=6)',
      '',
      '   Iteration 1:',
      '   h(x) = 0 + 0×x = 0',
      '   Errors: [2, 4, 6]',
      '   ∇J(θ₀) = (1/3)(2+4+6) = 4',
      '   ∇J(θ₁) = (1/3)(2×1+4×2+6×3) = 8',
      '   Updates: θ₀ = 0 - 0.01×4 = -0.04, θ₁ = 0 - 0.01×8 = -0.08',
      '',
      '🎨 VISUALIZATION CONCEPTS:',
      '   Cost Surface: 3D landscape with parameters as x,y axes',
      '   Gradient Vector: Arrow pointing uphill (steepest ascent)',
      '   Descent Path: Trajectory from initialization to minimum',
      '   Learning Rate Effect: Step size along gradient direction',
      '   Local vs Global Minima: Multiple valleys in cost surface',
      '',
      '🔍 ALGORITHM COMPARISON:',
      '',
      '   🏃 CONVERGENCE SPEED:',
      '   Adam > RMSprop > Momentum > SGD > BGD',
      '',
      '   📊 MEMORY USAGE:',
      '   BGD > Mini-batch > SGD',
      '   Adam > RMSprop > Momentum > Vanilla GD',
      '',
      '   🎯 HYPERPARAMETER SENSITIVITY:',
      '   SGD (high) > BGD > Adam > RMSprop (low)',
      '',
      '   🔧 EASE OF TUNING:',
      '   Adam (easy) > RMSprop > Momentum > SGD (hard)',
      '',
      '⚙️ HYPERPARAMETER TUNING GUIDELINES:',
      '',
      '   📈 LEARNING RATE STRATEGIES:',
      '   • Fixed: Constant throughout training',
      '   • Step Decay: Reduce by factor every N epochs',
      '   • Exponential Decay: α = α₀ × e^(-kt)',
      '   • Cosine Annealing: α = α₀/2(1 + cos(πt/T))',
      '   • Warm Restart: Periodic resets with smaller learning rates',
      '',
      '   🎯 BATCH SIZE EFFECTS:',
      '   • Small (8-32): Noisy gradients, better generalization',
      '   • Medium (64-256): Good balance, most common',
      '   • Large (512+): Stable training, may overfit',
      '',
      '⚠️ COMMON ISSUES & SOLUTIONS:',
      '',
      '   🌋 EXPLODING GRADIENTS:',
      '   Problem: Gradients become very large',
      '   Solutions: Gradient clipping, lower learning rate',
      '   Detection: NaN values, loss becomes inf',
      '',
      '   🕳️ VANISHING GRADIENTS:',
      '   Problem: Gradients become very small',
      '   Solutions: Better initialization, residual connections',
      '   Common: Deep neural networks, RNNs',
      '',
      '   🎯 SADDLE POINTS:',
      '   Problem: Gradient ≈ 0 but not minimum',
      '   Solutions: Momentum-based methods, noise injection',
      '   Detection: Loss plateau, slow convergence',
      '',
      '   🔄 OSCILLATION:',
      '   Problem: Parameters bounce around minimum',
      '   Solutions: Reduce learning rate, use momentum',
      '   Cause: Learning rate too high',
      '',
      '📋 ALGORITHM SELECTION GUIDE:',
      '',
      '   🚀 GENERAL PURPOSE: Adam (good default choice)',
      '   🏃 FAST PROTOTYPING: SGD with momentum',
      '   🎯 PRODUCTION SYSTEMS: AdamW with weight decay',
      '   📊 COMPUTER VISION: SGD with momentum + learning rate scheduling',
      '   🧠 NLP/TRANSFORMERS: AdamW with warm-up + cosine decay',
      '   📈 SPARSE DATA: Adagrad or RMSprop',
      '',
      '💻 IMPLEMENTATION CONSIDERATIONS:',
      '   • Numerical Stability: Add small ε to denominators',
      '   • Vectorization: Use matrix operations for efficiency',
      '   • Memory Management: Store running averages efficiently',
      '   • Learning Rate Schedules: Implement decay strategies',
      '   • Gradient Clipping: Prevent exploding gradients',
      '   • Checkpointing: Save best parameters during training',
      '',
      '📈 MONITORING & DEBUGGING:',
      '   • Plot loss curves: Training vs validation',
      '   • Track gradient norms: Detect vanishing/exploding',
      '   • Monitor learning rate: Ensure proper scheduling',
      '   • Visualize parameter updates: Check convergence',
      '   • Record convergence metrics: Time to target accuracy'
    ]
  }
];

const AICard: React.FC = () => {
  const [expanded, setExpanded] = useState<string | null>(null);
  const toggle = (name: string) => setExpanded(prev => prev === name ? null : name);

  return (
    <div className="systems-container">
      {topics.map(topic => (
        <div key={topic.name} className="system-card" onClick={() => toggle(topic.name)}>
          <div className="system-card-header">
            <h4>{topic.name}</h4>
            <span className="toggle-arrow">{expanded === topic.name ? '▲' : '▼'}</span>
          </div>
          {expanded === topic.name && (
            <div className="system-card-details">
              <ul>
                {topic.details.map((d, i) => <li key={i}>{d}</li>)}
              </ul>
            </div>
          )}
        </div>
      ))}
    </div>
  );
};

export default AICard;
