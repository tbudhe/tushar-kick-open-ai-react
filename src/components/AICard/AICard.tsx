import React, { useState } from 'react';
import '../../css/Systems.css';

interface AITopic {
  name: string;
  details: string[];
}

const topics: AITopic[] = [
  {
    name: 'Supervised Learning',
    details: [
      'ğŸ¯ Definition: Trains on labeled input-output pairs to learn mapping f: X â†’ Y',
      'ğŸ“Š Goal: Make accurate predictions on new, unseen data',
      '',
      'ğŸ”¢ LINEAR REGRESSION:',
      '   Formula: y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™ + Îµ',
      '   Cost Function: MSE = (1/2m) Î£(hÎ¸(xâ½â±â¾) - yâ½â±â¾)Â²',
      '   Example: Predicting house prices based on size, location, bedrooms',
      '   Visual: Straight line fitting through data points',
      '',
      'ğŸ“ˆ LOGISTIC REGRESSION:',
      '   Formula: p = 1/(1 + e^(-z)) where z = Î²â‚€ + Î²â‚xâ‚ + ... + Î²â‚™xâ‚™',
      '   Cost Function: J(Î¸) = -(1/m)[Î£yâ½â±â¾log(hÎ¸(xâ½â±â¾)) + (1-yâ½â±â¾)log(1-hÎ¸(xâ½â±â¾))]',
      '   Example: Email spam detection (spam=1, not spam=0)',
      '   Visual: S-shaped sigmoid curve',
      '',
      'ğŸ¯ SUPPORT VECTOR MACHINE (SVM):',
      '   Formula: f(x) = sign(Î£Î±áµ¢yáµ¢K(xáµ¢,x) + b)',
      '   Objective: max margin = 2/||w||',
      '   Kernel Trick: K(x,z) = Ï†(x)áµ€Ï†(z) (RBF: K(x,z) = exp(-Î³||x-z||Â²))',
      '   Example: Image classification, text categorization',
      '   Visual: Hyperplane separating classes with maximum margin',
      '',
      'ğŸŒ³ DECISION TREES:',
      '   Split Criterion: Gini = 1 - Î£páµ¢Â² or Entropy = -Î£páµ¢logâ‚‚(páµ¢)',
      '   Information Gain: IG = H(parent) - Î£(|child|/|parent|)H(child)',
      '   Example: Medical diagnosis (fever>38Â°C â†’ cold vs flu)',
      '   Visual: Tree structure with if-then rules',
      '',
      'ğŸŒ² RANDOM FOREST:',
      '   Formula: Å· = (1/B)Î£Táµ¦(x) for regression, majority vote for classification',
      '   Bootstrap: Sample with replacement, use âˆšp features per split',
      '   Example: Credit scoring, feature importance ranking',
      '   Visual: Multiple trees voting on final prediction',
      '',
      'ğŸ§  NEURAL NETWORKS:',
      '   Forward Pass: aË¡ = Ïƒ(WË¡aË¡â»Â¹ + bË¡)',
      '   Backpropagation: âˆ‚C/âˆ‚w = Î´áµƒË¡â»Â¹áµ€, Î´Ë¡ = (WË¡âºÂ¹)áµ€Î´Ë¡âºÂ¹ âŠ™ Ïƒ\'(zË¡)',
      '   Activation: ReLU = max(0,x), Sigmoid = 1/(1+eâ»Ë£), Tanh = (eË£-eâ»Ë£)/(eË£+eâ»Ë£)',
      '   Example: Image recognition, natural language processing',
      '   Visual: Layered network of interconnected nodes',
      '',
      'ğŸ² K-NEAREST NEIGHBORS (KNN):',
      '   Distance: Euclidean = âˆšÎ£(xáµ¢-yáµ¢)Â², Manhattan = Î£|xáµ¢-yáµ¢|',
      '   Prediction: Majority vote (classification) or average (regression) of k neighbors',
      '   Example: Recommendation systems, pattern recognition',
      '   Visual: Points clustered around similar neighbors',
      '',
      'ğŸ“‹ EVALUATION METRICS:',
      '   Accuracy = (TP+TN)/(TP+TN+FP+FN)',
      '   Precision = TP/(TP+FP), Recall = TP/(TP+FN)',
      '   F1-Score = 2Ã—(PrecisionÃ—Recall)/(Precision+Recall)',
      '   ROC-AUC: Area under Receiver Operating Characteristic curve'
    ]
  },
  {
    name: 'Unsupervised Learning',
    details: [
      'ğŸ” Definition: Discovers hidden patterns in unlabeled data without target variables',
      'ğŸ¯ Goal: Find structure, reduce dimensions, group similar data points',
      '',
      'ğŸ¯ K-MEANS CLUSTERING:',
      '   Algorithm: Minimize WCSS = Î£Î£||xáµ¢ - Î¼â±¼||Â² where Î¼â±¼ is centroid j',
      '   Steps: 1) Initialize k centroids 2) Assign points 3) Update centroids 4) Repeat',
      '   Distance: Euclidean = âˆšÎ£(xáµ¢-yáµ¢)Â²',
      '   Example: Customer segmentation, market research, image compression',
      '   Visual: Points grouped around k cluster centers',
      '',
      'ğŸŒ² HIERARCHICAL CLUSTERING:',
      '   Agglomerative: Bottom-up, merge closest clusters',
      '   Divisive: Top-down, split clusters recursively',
      '   Linkage: Single (min), Complete (max), Average, Ward (minimize variance)',
      '   Example: Phylogenetic trees, social network analysis',
      '   Visual: Dendrogram showing cluster hierarchy',
      '',
      'ğŸ¯ DBSCAN (Density-Based):',
      '   Core Point: |N(p)| â‰¥ minPts within Îµ radius',
      '   Border Point: In Îµ-neighborhood of core point',
      '   Noise Point: Neither core nor border',
      '   Example: Anomaly detection, irregular cluster shapes',
      '   Visual: Dense regions connected, outliers as noise',
      '',
      'ğŸ“ PRINCIPAL COMPONENT ANALYSIS (PCA):',
      '   Formula: Y = XW where W are eigenvectors of covariance matrix',
      '   Variance Explained: Î»áµ¢/Î£Î»â±¼ for eigenvalue Î»áµ¢',
      '   Steps: 1) Standardize 2) Covariance matrix 3) Eigendecomposition 4) Project',
      '   Example: Image compression, data visualization, feature reduction',
      '   Visual: Data projected onto principal component axes',
      '',
      'ğŸ“Š t-SNE (t-Distributed Stochastic Neighbor Embedding):',
      '   High-D Similarity: pâ±¼|áµ¢ = exp(-||xáµ¢-xâ±¼||Â²/2Ïƒáµ¢Â²)/Î£â‚–â‰ áµ¢exp(-||xáµ¢-xâ‚–||Â²/2Ïƒáµ¢Â²)',
      '   Low-D Similarity: qáµ¢â±¼ = (1+||yáµ¢-yâ±¼||Â²)â»Â¹/Î£â‚–â‰ â‚—(1+||yâ‚–-yâ‚—||Â²)â»Â¹',
      '   Cost: KL(P||Q) = Î£áµ¢Î£â±¼páµ¢â±¼log(páµ¢â±¼/qáµ¢â±¼)',
      '   Example: High-dimensional data visualization, gene expression',
      '   Visual: Non-linear embedding preserving local structure',
      '',
      'ğŸ›’ ASSOCIATION RULES (Market Basket):',
      '   Support: sup(A) = |A|/|D| (frequency of itemset A)',
      '   Confidence: conf(Aâ†’B) = sup(AâˆªB)/sup(A)',
      '   Lift: lift(Aâ†’B) = conf(Aâ†’B)/sup(B)',
      '   Apriori Algorithm: Generate frequent itemsets, extract rules',
      '   Example: "People who buy bread also buy butter" (grocery stores)',
      '   Visual: Network of item associations with strength indicators',
      '',
      'ğŸ¯ GAUSSIAN MIXTURE MODELS (GMM):',
      '   Formula: p(x) = Î£â‚–Ï€â‚–ğ’©(x|Î¼â‚–,Î£â‚–) where Ï€â‚– are mixing coefficients',
      '   EM Algorithm: E-step (responsibilities), M-step (parameters)',
      '   Log-likelihood: â„“ = Î£áµ¢log(Î£â‚–Ï€â‚–ğ’©(xáµ¢|Î¼â‚–,Î£â‚–))',
      '   Example: Image segmentation, density estimation',
      '   Visual: Overlapping Gaussian distributions forming clusters',
      '',
      'ğŸŒ UNIFORM MANIFOLD APPROXIMATION (UMAP):',
      '   Theory: Riemannian manifold learning with topological data analysis',
      '   Fuzzy Simplicial Sets: Probabilistic topology representation',
      '   Optimization: Cross-entropy between high/low dimensional representations',
      '   Example: Single-cell genomics, large-scale data visualization',
      '   Visual: Preserves both local and global structure better than t-SNE',
      '',
      'ğŸ“‹ EVALUATION METRICS:',
      '   Silhouette Score: (b-a)/max(a,b) where a=intra, b=inter cluster distance',
      '   Davies-Bouldin Index: (1/k)Î£áµ¢maxâ±¼â‰ áµ¢(Ïƒáµ¢+Ïƒâ±¼)/d(cáµ¢,câ±¼) (lower is better)',
      '   Calinski-Harabasz: Between-cluster variance / Within-cluster variance',
      '   Elbow Method: Plot WCSS vs k, find "elbow" point'
    ]
  },
  {
    name: 'Reinforcement Learning',
    details: [
      'ğŸ® Definition: Agent learns optimal actions through trial-and-error interactions with environment',
      'ğŸ† Goal: Maximize cumulative reward over time through optimal policy Ï€*',
      'ğŸ”‘ Core Elements: State (S), Action (A), Reward (R), Policy (Ï€), Value (V)',
      '',
      'ğŸ“Š MARKOV DECISION PROCESS (MDP):',
      '   Components: <S, A, P, R, Î³> (States, Actions, Transitions, Rewards, Discount)',
      '   Bellman Equation: V*(s) = max_a Î£s\' P(s\'|s,a)[R(s,a,s\') + Î³V*(s\')]',
      '   Policy: Ï€(a|s) = probability of taking action a in state s',
      '   Visual: State-action diagram with transition probabilities',
      '',
      'ğŸ¯ Q-LEARNING (Model-Free):',
      '   Update Rule: Q(s,a) â† Q(s,a) + Î±[r + Î³max_a\'Q(s\',a\') - Q(s,a)]',
      '   Îµ-Greedy: Choose random action with probability Îµ, else argmax_a Q(s,a)',
      '   Convergence: Guaranteed if all state-action pairs visited infinitely often',
      '   Example: Game playing (Pac-Man), robot navigation',
      '   Visual: Q-table with state-action values, policy derived from max Q-values',
      '',
      'ğŸ”„ SARSA (State-Action-Reward-State-Action):',
      '   Update Rule: Q(s,a) â† Q(s,a) + Î±[r + Î³Q(s\',a\') - Q(s,a)]',
      '   On-Policy: Updates based on actual policy being followed',
      '   Difference from Q-Learning: Uses actual next action a\' instead of max',
      '   Example: Safe robot control, conservative exploration',
      '   Visual: Agent follows policy while learning, more conservative updates',
      '',
      'ğŸ§  DEEP Q-NETWORKS (DQN):',
      '   Neural Network: Q(s,a;Î¸) â‰ˆ Q*(s,a) where Î¸ are network parameters',
      '   Loss Function: L(Î¸) = E[(r + Î³max_a\'Q(s\',a\';Î¸â») - Q(s,a;Î¸))Â²]',
      '   Experience Replay: Store transitions in buffer, sample mini-batches',
      '   Target Network: Î¸â» updated periodically to stabilize training',
      '   Example: Atari games, complex state spaces',
      '   Visual: Neural network approximating Q-function for high-dimensional states',
      '',
      'ğŸ­ POLICY GRADIENT METHODS:',
      '   REINFORCE: âˆ‡J(Î¸) = E[âˆ‡log Ï€(a|s;Î¸) Q^Ï€(s,a)]',
      '   Actor-Critic: Actor updates policy, Critic estimates value function',
      '   Advantage: A(s,a) = Q(s,a) - V(s) (reduces variance)',
      '   Example: Continuous control, robotics, complex action spaces',
      '   Visual: Direct policy optimization without value function intermediary',
      '',
      'ğŸš€ PROXIMAL POLICY OPTIMIZATION (PPO):',
      '   Objective: L^CLIP(Î¸) = E[min(r_t(Î¸)Ã‚_t, clip(r_t(Î¸),1-Îµ,1+Îµ)Ã‚_t)]',
      '   Ratio: r_t(Î¸) = Ï€_Î¸(a_t|s_t)/Ï€_Î¸_old(a_t|s_t)',
      '   Clipping: Prevents large policy updates, maintains stability',
      '   Example: OpenAI Five (Dota 2), robotics, continuous control',
      '   Visual: Clipped objective function preventing destructive updates',
      '',
      'ğŸª ACTOR-CRITIC METHODS:',
      '   Actor: âˆ‡J(Î¸) = E[âˆ‡log Ï€(a|s;Î¸) A(s,a)]',
      '   Critic: V(s;w) â‰ˆ V^Ï€(s), updated via TD learning',
      '   A3C: Asynchronous Advantage Actor-Critic with multiple workers',
      '   A2C: Synchronous version of A3C',
      '   Example: Complex environments, parallel training',
      '   Visual: Two networks - actor (policy) and critic (value) working together',
      '',
      'ğŸŒŸ DEEP DETERMINISTIC POLICY GRADIENT (DDPG):',
      '   Deterministic Policy: Î¼(s;Î¸^Î¼) instead of stochastic Ï€(a|s)',
      '   Critic Update: L = E[(r + Î³Q(s\',Î¼(s\');Î¸^Q) - Q(s,a;Î¸^Q))Â²]',
      '   Actor Update: âˆ‡J = E[âˆ‡_a Q(s,a;Î¸^Q)|_{a=Î¼(s)} âˆ‡Î¼(s;Î¸^Î¼)]',
      '   Exploration: Add noise to deterministic policy',
      '   Example: Continuous control tasks, robotic manipulation',
      '   Visual: Deterministic policy mapping states directly to actions',
      '',
      'ğŸ² MULTI-ARMED BANDITS:',
      '   UCB1: Select action with highest UCB_t(a) = QÌ„_t(a) + câˆš(ln t/N_t(a))',
      '   Thompson Sampling: Sample from posterior distribution of action values',
      '   Îµ-Greedy: Explore randomly with probability Îµ',
      '   Example: A/B testing, recommendation systems, online advertising',
      '   Visual: Arms (actions) with unknown reward distributions',
      '',
      'ğŸ“‹ EVALUATION METRICS:',
      '   Cumulative Reward: G_t = Î£_{k=0}^âˆ Î³^k R_{t+k+1}',
      '   Sample Efficiency: Learning speed (episodes to convergence)',
      '   Policy Performance: Average reward per episode',
      '   Exploration Efficiency: Coverage of state-action space'
    ]
  },
  {
    name: 'Agentic AI vs Generative AI',
    details: [
      'ğŸ¤– AGENTIC AI (Goal-Oriented, Action-Taking):',
      '   Definition: AI systems that can take autonomous actions to achieve specific goals',
      '   Core Capability: Decision-making, planning, and executing actions in environments',
      '   Architecture: Agent + Environment + Action Space + Reward Function',
      '   Learning: Through interaction, trial-and-error, reinforcement learning',
      '   Examples: Autonomous vehicles, trading bots, game-playing AI (AlphaGo)',
      '   Visual: Agent interacting with environment, taking actions based on observations',
      '',
      'ğŸ¨ GENERATIVE AI (Content Creation):',
      '   Definition: AI systems that create new content (text, images, audio, code)',
      '   Core Capability: Pattern recognition and synthesis from training data',
      '   Architecture: Encoder-Decoder, Transformers, GANs, Diffusion Models',
      '   Learning: Through large datasets, supervised/unsupervised learning',
      '   Examples: ChatGPT, DALL-E, Midjourney, GitHub Copilot, Stable Diffusion',
      '   Visual: Neural network generating new content from learned patterns',
      '',
      'ğŸ” KEY DIFFERENCES:',
      '',
      'ğŸ¯ PURPOSE & GOALS:',
      '   Agentic AI: Optimize outcomes, maximize rewards, achieve objectives',
      '   Generative AI: Create realistic, diverse, high-quality content',
      '',
      'âš™ï¸ INTERACTION MODEL:',
      '   Agentic AI: Interactive, real-time decision making in dynamic environments',
      '   Generative AI: One-shot or iterative content generation from prompts',
      '',
      'ğŸ“Š TRAINING APPROACH:',
      '   Agentic AI: Reinforcement Learning, Online Learning, Trial-and-Error',
      '   Generative AI: Supervised Learning, Self-Supervised, Large-Scale Pretraining',
      '',
      'ğŸ® ENVIRONMENT:',
      '   Agentic AI: Dynamic, reactive environments (games, real world, simulations)',
      '   Generative AI: Static datasets, text corpora, image collections',
      '',
      'ğŸ“ˆ EVALUATION METRICS:',
      '   Agentic AI: Reward/utility maximization, success rate, efficiency',
      '   Generative AI: Quality, diversity, coherence, human preference',
      '',
      'ğŸ”„ FEEDBACK LOOP:',
      '   Agentic AI: Immediate environment feedback, reward signals',
      '   Generative AI: Human feedback, preference learning, RLHF',
      '',
      'âš¡ REAL-TIME REQUIREMENTS:',
      '   Agentic AI: Often requires real-time decision making',
      '   Generative AI: Can operate with longer inference times for quality',
      '',
      'ğŸ² EXPLORATION vs EXPLOITATION:',
      '   Agentic AI: Critical balance between exploring new strategies and exploiting known good ones',
      '   Generative AI: Exploration through randomness/sampling for diversity',
      '',
      'ğŸš€ EMERGING HYBRID APPROACHES:',
      '   Agent + LLM: Language agents that can reason and take actions',
      '   Generative Agents: AI agents that can generate plans and content',
      '   Examples: ChatGPT with plugins, AutoGPT, LangChain agents',
      '   Visual: Integration of both paradigms for comprehensive AI systems',
      '',
      'ğŸ“‹ PRACTICAL APPLICATIONS:',
      '   Agentic AI: Robotics, autonomous systems, algorithmic trading, game AI',
      '   Generative AI: Content creation, code generation, art, writing assistance',
      '   Hybrid: AI assistants, creative collaborators, intelligent automation'
    ]
  },
  {
    name: 'Entropy vs Gini Index',
    details: [
      'ğŸŒ³ DECISION TREE SPLIT CRITERIA COMPARISON:',
      '   Purpose: Both measure impurity/uncertainty in data splits for decision trees',
      '   Goal: Find optimal splits that maximize information gain and purity',
      '',
      'ğŸ“Š ENTROPY (Information Theory Based):',
      '   Formula: H(S) = -Î£áµ¢ páµ¢ Ã— logâ‚‚(páµ¢)',
      '   Range: 0 (pure) to logâ‚‚(n) where n = number of classes',
      '   Binary Classification: H(S) = -pâ‚logâ‚‚(pâ‚) - pâ‚‚logâ‚‚(pâ‚‚)',
      '   Maximum: logâ‚‚(2) = 1 for binary, occurs when pâ‚ = pâ‚‚ = 0.5',
      '   Interpretation: Average number of bits needed to encode class information',
      '   Example: For [50% Class A, 50% Class B]: H = -0.5Ã—logâ‚‚(0.5) - 0.5Ã—logâ‚‚(0.5) = 1',
      '',
      'ğŸ¯ GINI INDEX (Probability Based):',
      '   Formula: Gini(S) = 1 - Î£áµ¢ páµ¢Â²',
      '   Range: 0 (pure) to 0.5 (maximum impurity for binary)',
      '   Binary Classification: Gini(S) = 1 - pâ‚Â² - pâ‚‚Â²',
      '   Maximum: 0.5 for binary, occurs when pâ‚ = pâ‚‚ = 0.5',
      '   Interpretation: Probability of misclassifying a randomly chosen element',
      '   Example: For [50% Class A, 50% Class B]: Gini = 1 - 0.5Â² - 0.5Â² = 0.5',
      '',
      'ğŸ” KEY DIFFERENCES:',
      '',
      'ğŸ“ˆ MATHEMATICAL PROPERTIES:',
      '   Entropy: Logarithmic function, more sensitive to probability changes',
      '   Gini: Quadratic function, computationally simpler (no logarithms)',
      '   Entropy: Higher penalty for very uneven splits',
      '   Gini: More balanced penalty across probability ranges',
      '',
      'âš¡ COMPUTATIONAL COMPLEXITY:',
      '   Entropy: Requires logarithm calculation (more expensive)',
      '   Gini: Simple arithmetic operations (faster)',
      '   Performance: Gini typically 2-3x faster to compute',
      '',
      'ğŸ“Š SENSITIVITY ANALYSIS:',
      '   Entropy: More sensitive to small probability changes near 0 or 1',
      '   Gini: More stable, less sensitive to extreme probabilities',
      '   Split Selection: Entropy tends to favor more balanced splits',
      '   Practical Impact: Usually produce similar tree structures',
      '',
      'ğŸ² PRACTICAL EXAMPLES:',
      '',
      '   Dataset: [80% Class A, 20% Class B]',
      '   Entropy: H = -0.8Ã—logâ‚‚(0.8) - 0.2Ã—logâ‚‚(0.2) = 0.722',
      '   Gini: G = 1 - 0.8Â² - 0.2Â² = 1 - 0.64 - 0.04 = 0.32',
      '',
      '   Dataset: [90% Class A, 10% Class B]',
      '   Entropy: H = -0.9Ã—logâ‚‚(0.9) - 0.1Ã—logâ‚‚(0.1) = 0.469',
      '   Gini: G = 1 - 0.9Â² - 0.1Â² = 1 - 0.81 - 0.01 = 0.18',
      '',
      'ğŸŒŸ INFORMATION GAIN CALCULATION:',
      '   Information Gain: IG = H(parent) - Î£(|child|/|parent|) Ã— H(child)',
      '   Gini Gain: GG = Gini(parent) - Î£(|child|/|parent|) Ã— Gini(child)',
      '   Both aim to maximize gain (reduce impurity after split)',
      '',
      'ğŸš€ ALGORITHM PREFERENCES:',
      '   C4.5/C5.0: Uses Entropy (information gain ratio)',
      '   CART: Uses Gini Index by default',
      '   Random Forest: Often uses Gini for speed',
      '   scikit-learn: Gini default, Entropy available',
      '',
      'ğŸ“‹ DECISION GUIDELINES:',
      '   Use Entropy: When interpretability matters, theoretical analysis',
      '   Use Gini: When speed is critical, large datasets, production systems',
      '   Performance: Both typically yield similar accuracy',
      '   Default Choice: Gini for most practical applications'
    ]
  },
  {
    name: 'Linear Regression Deep Dive',
    details: [
      'ğŸ“ˆ DEFINITION & PURPOSE:',
      '   Goal: Find the best linear relationship between input features (X) and target (y)',
      '   Assumption: Linear relationship exists between variables',
      '   Output: Continuous numerical predictions',
      '',
      'ğŸ”¢ MATHEMATICAL FOUNDATION:',
      '',
      'ğŸ“Š SIMPLE LINEAR REGRESSION (1 Feature):',
      '   Model: y = Î²â‚€ + Î²â‚x + Îµ',
      '   Î²â‚€: y-intercept (bias term)',
      '   Î²â‚: slope (weight/coefficient)',
      '   Îµ: error term (noise)',
      '   Prediction: Å· = Î²â‚€ + Î²â‚x',
      '',
      'ğŸ¯ MULTIPLE LINEAR REGRESSION (n Features):',
      '   Model: y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™ + Îµ',
      '   Matrix Form: y = XÎ² + Îµ',
      '   X: [1, xâ‚, xâ‚‚, ..., xâ‚™] (design matrix with bias column)',
      '   Î²: [Î²â‚€, Î²â‚, Î²â‚‚, ..., Î²â‚™]áµ€ (parameter vector)',
      '',
      'ğŸ’° COST FUNCTION (Mean Squared Error):',
      '   MSE = (1/2m) Î£áµ¢â‚Œâ‚áµ (hÎ¸(xâ½â±â¾) - yâ½â±â¾)Â²',
      '   hÎ¸(xâ½â±â¾) = Î¸â‚€ + Î¸â‚xâ‚â½â±â¾ + ... + Î¸â‚™xâ‚™â½â±â¾',
      '   m: number of training examples',
      '   Goal: minimize J(Î¸) = MSE',
      '',
      'ğŸ§® ANALYTICAL SOLUTION (Normal Equation):',
      '   Î¸ = (Xáµ€X)â»Â¹Xáµ€y',
      '   Derivation: âˆ‡J(Î¸) = 0',
      '   âˆ‚J/âˆ‚Î¸ = Xáµ€XÎ¸ - Xáµ€y = 0',
      '   Pros: Exact solution, no learning rate needed',
      '   Cons: O(nÂ³) complexity, requires matrix inversion',
      '',
      'âš¡ GRADIENT DESCENT APPROACH:',
      '',
      'ğŸ“‰ BATCH GRADIENT DESCENT:',
      '   Update Rule: Î¸â±¼ := Î¸â±¼ - Î±(âˆ‚J/âˆ‚Î¸â±¼)',
      '   Partial Derivative: âˆ‚J/âˆ‚Î¸â±¼ = (1/m) Î£áµ¢â‚Œâ‚áµ (hÎ¸(xâ½â±â¾) - yâ½â±â¾)xâ±¼â½â±â¾',
      '   Î±: learning rate (typically 0.01 to 0.3)',
      '   Convergence: When ||âˆ‡J(Î¸)|| < tolerance',
      '',
      'ğŸ”„ STOCHASTIC GRADIENT DESCENT (SGD):',
      '   Update per example: Î¸â±¼ := Î¸â±¼ - Î±(hÎ¸(xâ½â±â¾) - yâ½â±â¾)xâ±¼â½â±â¾',
      '   Faster updates, more noisy convergence',
      '   Good for large datasets (m > 10,000)',
      '',
      'ğŸ¨ VISUAL REPRESENTATION:',
      '   Simple Linear: Straight line y = mx + b on 2D plot',
      '   Multiple Linear: Hyperplane in n-dimensional space',
      '   Cost Function: Convex bowl shape (single global minimum)',
      '   Gradient Descent: Ball rolling down the cost surface',
      '',
      'ğŸ  PRACTICAL EXAMPLE - House Price Prediction:',
      '',
      '   Features: Size (sq ft), Bedrooms, Age, Location Score',
      '   Model: Price = Î²â‚€ + Î²â‚Ã—Size + Î²â‚‚Ã—Bedrooms + Î²â‚ƒÃ—Age + Î²â‚„Ã—Location',
      '',
      '   Sample Data:',
      '   House 1: Size=1500, Beds=3, Age=10, Loc=8 â†’ Price=$300K',
      '   House 2: Size=2000, Beds=4, Age=5, Loc=9 â†’ Price=$450K',
      '',
      '   After Training:',
      '   Price = 50000 + 150Ã—Size + 10000Ã—Beds - 2000Ã—Age + 5000Ã—Loc',
      '   Interpretation: Each sq ft adds $150, each bedroom adds $10K',
      '',
      'ğŸ“Š ASSUMPTIONS & REQUIREMENTS:',
      '   1. Linearity: Relationship between X and y is linear',
      '   2. Independence: Observations are independent',
      '   3. Homoscedasticity: Constant variance of residuals',
      '   4. Normality: Residuals are normally distributed',
      '   5. No Multicollinearity: Features not highly correlated',
      '',
      'âš ï¸ COMMON PROBLEMS & SOLUTIONS:',
      '   Overfitting: Use regularization (Ridge/Lasso)',
      '   Multicollinearity: Remove correlated features, use PCA',
      '   Non-linearity: Feature engineering, polynomial features',
      '   Outliers: Robust regression, outlier detection',
      '',
      'ğŸ”§ FEATURE ENGINEERING:',
      '   Polynomial Features: xâ‚, xâ‚‚, xâ‚Â², xâ‚‚Â², xâ‚xâ‚‚',
      '   Interaction Terms: xâ‚ Ã— xâ‚‚, xâ‚ Ã— xâ‚ƒ',
      '   Log Transform: log(x) for exponential relationships',
      '   Normalization: (x - Î¼)/Ïƒ for different scales',
      '',
      'ğŸ“ˆ EVALUATION METRICS:',
      '   MSE = (1/n) Î£(yáµ¢ - Å·áµ¢)Â²',
      '   RMSE = âˆšMSE (same units as target)',
      '   MAE = (1/n) Î£|yáµ¢ - Å·áµ¢| (robust to outliers)',
      '   RÂ² = 1 - (SS_res/SS_tot) (proportion of variance explained)',
      '',
      'ğŸ’» IMPLEMENTATION STEPS:',
      '   1. Data Preprocessing: Handle missing values, normalize',
      '   2. Feature Selection: Choose relevant features',
      '   3. Train-Test Split: Typically 80-20 or 70-30',
      '   4. Model Training: Fit using Normal Equation or GD',
      '   5. Evaluation: Calculate metrics on test set',
      '   6. Validation: Cross-validation for robustness'
    ]
  },
  {
    name: 'Logistic Regression Deep Dive',
    details: [
      'ğŸ¯ DEFINITION & PURPOSE:',
      '   Goal: Predict probability of binary/categorical outcomes (classification)',
      '   Output: Probability between 0 and 1',
      '   Decision Boundary: Linear separation in feature space',
      '   Applications: Email spam, medical diagnosis, marketing response',
      '',
      'ğŸ“Š FUNDAMENTAL CONCEPT:',
      '   Problem: Linear regression outputs unbounded values (-âˆ to +âˆ)',
      '   Solution: Map linear output to probability using sigmoid function',
      '   Advantage: Probabilistic interpretation of predictions',
      '',
      'ğŸ”¢ SIGMOID FUNCTION (LOGISTIC FUNCTION):',
      '   Formula: Ïƒ(z) = 1/(1 + e^(-z))',
      '   Input: z = Î¸â‚€ + Î¸â‚xâ‚ + Î¸â‚‚xâ‚‚ + ... + Î¸â‚™xâ‚™',
      '   Output Range: (0, 1)',
      '   Properties: S-shaped curve, differentiable, monotonic',
      '',
      'ğŸ“ˆ SIGMOID CURVE CHARACTERISTICS:',
      '   At z = 0: Ïƒ(0) = 1/(1 + eâ°) = 1/2 = 0.5',
      '   As z â†’ +âˆ: Ïƒ(z) â†’ 1',
      '   As z â†’ -âˆ: Ïƒ(z) â†’ 0',
      '   Derivative: Ïƒ\'(z) = Ïƒ(z)(1 - Ïƒ(z))',
      '   Maximum slope at z = 0',
      '',
      'ğŸ¯ LOGISTIC REGRESSION MODEL:',
      '   Hypothesis: h_Î¸(x) = Ïƒ(Î¸áµ€x) = 1/(1 + e^(-Î¸áµ€x))',
      '   Prediction: Å· = 1 if h_Î¸(x) â‰¥ 0.5, else 0',
      '   Decision Boundary: Î¸áµ€x = 0 (where h_Î¸(x) = 0.5)',
      '',
      'ğŸ“Š PROBABILITY INTERPRETATION:',
      '   P(y=1|x;Î¸) = h_Î¸(x) = sigmoid(Î¸áµ€x)',
      '   P(y=0|x;Î¸) = 1 - h_Î¸(x)',
      '   Odds Ratio: P(y=1)/P(y=0) = e^(Î¸áµ€x)',
      '   Log-Odds (Logit): ln(P(y=1)/P(y=0)) = Î¸áµ€x',
      '',
      'ğŸ’° COST FUNCTION (LOG-LIKELIHOOD):',
      '   Cannot use MSE (non-convex for sigmoid)',
      '   Use Maximum Likelihood Estimation (MLE)',
      '   Likelihood: L(Î¸) = âˆáµ¢â‚Œâ‚áµ P(yâ½â±â¾|xâ½â±â¾;Î¸)',
      '   Log-Likelihood: â„“(Î¸) = Î£áµ¢â‚Œâ‚áµ [yâ½â±â¾log(h_Î¸(xâ½â±â¾)) + (1-yâ½â±â¾)log(1-h_Î¸(xâ½â±â¾))]',
      '',
      'ğŸ¯ COST FUNCTION FORMULA:',
      '   J(Î¸) = -(1/m) Î£áµ¢â‚Œâ‚áµ [yâ½â±â¾log(h_Î¸(xâ½â±â¾)) + (1-yâ½â±â¾)log(1-h_Î¸(xâ½â±â¾))]',
      '   Individual Cost: cost(h_Î¸(x),y) = -ylog(h_Î¸(x)) - (1-y)log(1-h_Î¸(x))',
      '   Properties: Convex, differentiable, penalizes wrong predictions heavily',
      '',
      'âš¡ GRADIENT DESCENT:',
      '   Partial Derivative: âˆ‚J/âˆ‚Î¸â±¼ = (1/m) Î£áµ¢â‚Œâ‚áµ (h_Î¸(xâ½â±â¾) - yâ½â±â¾)xâ±¼â½â±â¾',
      '   Update Rule: Î¸â±¼ := Î¸â±¼ - Î±(âˆ‚J/âˆ‚Î¸â±¼)',
      '   Note: Same form as linear regression but h_Î¸(x) is sigmoid!',
      '   Learning Rate: Typically 0.01 to 1.0',
      '',
      'ğŸ§® DERIVATION OF GRADIENT:',
      '   âˆ‚Ïƒ/âˆ‚z = Ïƒ(z)(1-Ïƒ(z))',
      '   âˆ‚J/âˆ‚Î¸â±¼ = -(1/m) Î£áµ¢ [yâ½â±â¾/h_Î¸(xâ½â±â¾) - (1-yâ½â±â¾)/(1-h_Î¸(xâ½â±â¾))] Ã— âˆ‚h_Î¸/âˆ‚Î¸â±¼',
      '   Simplifies to: (1/m) Î£áµ¢ (h_Î¸(xâ½â±â¾) - yâ½â±â¾)xâ±¼â½â±â¾',
      '',
      'ğŸ¨ VISUAL REPRESENTATION:',
      '   1D Feature: S-curve separating two classes',
      '   2D Features: Linear decision boundary line',
      '   nD Features: Hyperplane in n-dimensional space',
      '   Cost Surface: Convex bowl (single global minimum)',
      '   Probability Contours: Smooth gradients from 0 to 1',
      '',
      'ğŸ“§ PRACTICAL EXAMPLE - Email Spam Detection:',
      '',
      '   Features: Word count ("free"), exclamation marks, caps ratio',
      '   Model: P(spam) = Ïƒ(Î¸â‚€ + Î¸â‚Ã—"free_count" + Î¸â‚‚Ã—exclamations + Î¸â‚ƒÃ—caps_ratio)',
      '',
      '   Sample Training:',
      '   Email 1: free=5, !=3, caps=0.8 â†’ Spam (y=1)',
      '   Email 2: free=0, !=1, caps=0.1 â†’ Not Spam (y=0)',
      '',
      '   After Training:',
      '   Î¸ = [-2.0, 1.5, 0.8, 2.0]',
      '   New Email: free=3, !=2, caps=0.6',
      '   z = -2.0 + 1.5Ã—3 + 0.8Ã—2 + 2.0Ã—0.6 = 4.3',
      '   P(spam) = 1/(1 + e^(-4.3)) = 0.986 â†’ 98.6% spam probability',
      '',
      'ğŸ”„ MULTICLASS CLASSIFICATION:',
      '   One-vs-Rest (OvR): Train n binary classifiers',
      '   One-vs-One (OvO): Train n(n-1)/2 classifiers',
      '   Softmax Regression: Direct multiclass extension',
      '   Softmax: P(y=k|x) = e^(Î¸â‚–áµ€x) / Î£â±¼e^(Î¸â±¼áµ€x)',
      '',
      'ğŸ“Š ASSUMPTIONS & REQUIREMENTS:',
      '   1. Linear relationship between logit and features',
      '   2. Independence of observations',
      '   3. No severe multicollinearity',
      '   4. Large sample size (at least 10 events per parameter)',
      '   5. No extreme outliers',
      '',
      'âš ï¸ COMMON ISSUES & SOLUTIONS:',
      '   Perfect Separation: Use regularization (L1/L2)',
      '   Multicollinearity: Remove correlated features',
      '   Outliers: Robust scaling, outlier detection',
      '   Imbalanced Data: SMOTE, class weights, threshold tuning',
      '',
      'ğŸ”§ REGULARIZATION:',
      '   L1 (Lasso): J(Î¸) + Î»Î£|Î¸â±¼| (feature selection)',
      '   L2 (Ridge): J(Î¸) + Î»Î£Î¸â±¼Â² (prevents overfitting)',
      '   Elastic Net: Combination of L1 and L2',
      '',
      'ğŸ“ˆ EVALUATION METRICS:',
      '   Accuracy = (TP + TN)/(TP + TN + FP + FN)',
      '   Precision = TP/(TP + FP)',
      '   Recall = TP/(TP + FN)',
      '   F1-Score = 2Ã—(PrecisionÃ—Recall)/(Precision+Recall)',
      '   AUC-ROC: Area under ROC curve',
      '   Log-Loss: -(1/n)Î£[yáµ¢log(páµ¢) + (1-yáµ¢)log(1-páµ¢)]',
      '',
      'ğŸ¯ DECISION THRESHOLD TUNING:',
      '   Default: 0.5 threshold',
      '   High Precision: Increase threshold (fewer false positives)',
      '   High Recall: Decrease threshold (fewer false negatives)',
      '   ROC Curve: Plot TPR vs FPR for all thresholds',
      '',
      'ğŸ’» IMPLEMENTATION STEPS:',
      '   1. Data Preprocessing: Handle missing values, encode categoricals',
      '   2. Feature Scaling: Standardize for better convergence',
      '   3. Train-Test Split: Stratified split for balanced classes',
      '   4. Model Training: Gradient descent or Newton-Raphson',
      '   5. Threshold Tuning: Optimize based on business requirements',
      '   6. Evaluation: Multiple metrics, cross-validation'
    ]
  },
  {
    name: 'ğŸ¯ Softmax Function Deep Dive',
    details: [
      'ğŸ§® MATHEMATICAL FOUNDATION:',
      '   Formula: Ïƒ(z_i) = e^(z_i) / Î£(j=1 to K) e^(z_j)',
      '   Where: z_i = input for class i, K = total classes',
      '   Output: Probability distribution where Î£ Ïƒ(z_i) = 1',
      '   Properties: All values âˆˆ [0,1], differentiable, smooth',
      '',
      'ğŸ›ï¸ TEMPERATURE PARAMETER:',
      '   Modified Formula: Ïƒ(z_i) = e^(z_i/T) / Î£(j=1 to K) e^(z_j/T)',
      '   T â†’ 0: Becomes argmax (one-hot distribution)',
      '   T â†’ âˆ: Becomes uniform distribution (1/K for all classes)',
      '   T = 1: Standard softmax',
      '   Use Cases: Controlling confidence, knowledge distillation',
      '',
      'ğŸ“Š PRACTICAL EXAMPLE - IMAGE CLASSIFICATION:',
      '   Raw Model Outputs (logits): [Cat: 2.0, Dog: 1.0, Bird: 0.1]',
      '   Exponentials: [e^2.0 = 7.39, e^1.0 = 2.72, e^0.1 = 1.11]',
      '   Sum: 7.39 + 2.72 + 1.11 = 11.22',
      '   Probabilities: [Cat: 65.9%, Dog: 24.2%, Bird: 9.9%]',
      '   Interpretation: Model is most confident about "Cat"',
      '',
      'ğŸ”¥ KEY PROPERTIES:',
      '   1. Probability Distribution: All outputs sum to 1',
      '   2. Exponential Amplification: Emphasizes maximum values',
      '   3. Differentiable: Smooth gradients for backpropagation',
      '   4. Monotonic: Preserves relative ordering of inputs',
      '   5. Scale Invariant: Adding constant to all inputs unchanged output',
      '',
      'ğŸ¯ CROSS-ENTROPY LOSS CONNECTION:',
      '   Loss Function: L = -Î£(i=1 to K) y_i Ã— log(Ïƒ(z_i))',
      '   Gradient: âˆ‚L/âˆ‚z_i = Ïƒ(z_i) - y_i',
      '   Beautiful Property: Gradient = predicted_prob - true_prob',
      '   Interpretation: Directly optimizes probability predictions',
      '',
      'âš ï¸ NUMERICAL STABILITY:',
      '   Problem: Large values cause overflow (e^1000 = âˆ)',
      '   Solution: Subtract maximum value before computation',
      '   Stable Formula: z\' = z - max(z), then apply softmax to z\'',
      '   Mathematical Equivalence: Result unchanged, but prevents overflow',
      '   Implementation: Always use this trick in production code',
      '',
      'ğŸš€ APPLICATIONS:',
      '   â€¢ Multi-class Classification: Final layer of neural networks',
      '   â€¢ Attention Mechanisms: Transformer models, seq2seq',
      '   â€¢ Reinforcement Learning: Action probability distributions',
      '   â€¢ Natural Language Processing: Next word prediction',
      '   â€¢ Computer Vision: Object detection, semantic segmentation',
      '   â€¢ Recommendation Systems: Item probability scoring',
      '',
      'ğŸ”„ SOFTMAX vs SIGMOID:',
      '   Sigmoid: Binary classification, independent probabilities',
      '   Softmax: Multi-class classification, mutually exclusive probabilities',
      '   Sigmoid: Ïƒ(z) = 1/(1 + e^(-z)), output âˆˆ [0,1]',
      '   Softmax: Generalizes sigmoid to multiple classes',
      '   Use Case: Sigmoid for multi-label, Softmax for multi-class',
      '',
      'ğŸ’» IMPLEMENTATION EXAMPLE:',
      '   def softmax(z):',
      '       # Numerical stability',
      '       z_shifted = z - np.max(z)',
      '       exp_z = np.exp(z_shifted)',
      '       return exp_z / np.sum(exp_z)',
      '   ',
      '   # Usage in neural network',
      '   logits = model(x)  # Raw outputs',
      '   probabilities = softmax(logits)  # Convert to probabilities',
      '   prediction = np.argmax(probabilities)  # Get predicted class'
    ]
  },
  {
    name: 'ğŸ›¡ï¸ Support Vector Machine (SVM) Deep Dive',
    details: [
      'ğŸ¯ DEFINITION & CORE CONCEPT:',
      '   Goal: Find optimal hyperplane that separates classes with maximum margin',
      '   Key Idea: Maximize distance between decision boundary and closest points',
      '   Support Vectors: Data points closest to the hyperplane (critical for model)',
      '   Applications: Text classification, image recognition, bioinformatics',
      '',
      'ğŸ“ MATHEMATICAL FOUNDATION:',
      '',
      'ğŸ” LINEAR SVM (SEPARABLE CASE):',
      '   Decision Function: f(x) = sign(wÂ·x + b)',
      '   Hyperplane Equation: wÂ·x + b = 0',
      '   Where: w = weight vector (normal to hyperplane)',
      '         b = bias term (shifts hyperplane)',
      '         x = input feature vector',
      '',
      'ğŸ“ MARGIN CALCULATION:',
      '   Geometric Margin: Î³ = |wÂ·x + b|/||w||',
      '   Functional Margin: Î³Ìƒ = y(wÂ·x + b)',
      '   Maximum Margin: M = 2/||w|| (distance between support vectors)',
      '   Constraint: yáµ¢(wÂ·xáµ¢ + b) â‰¥ 1 for all training points',
      '',
      'ğŸ¯ OPTIMIZATION PROBLEM (PRIMAL FORM):',
      '   Objective: minimize (1/2)||w||Â² subject to yáµ¢(wÂ·xáµ¢ + b) â‰¥ 1',
      '   Quadratic Programming: Convex optimization problem',
      '   Lagrangian: L = (1/2)||w||Â² - Î£áµ¢Î±áµ¢[yáµ¢(wÂ·xáµ¢ + b) - 1]',
      '   KKT Conditions: Î±áµ¢ â‰¥ 0, Î±áµ¢[yáµ¢(wÂ·xáµ¢ + b) - 1] = 0',
      '',
      'ğŸ”„ DUAL FORMULATION:',
      '   Objective: maximize Î£áµ¢Î±áµ¢ - (1/2)Î£áµ¢Î£â±¼Î±áµ¢Î±â±¼yáµ¢yâ±¼(xáµ¢Â·xâ±¼)',
      '   Subject to: Î£áµ¢Î±áµ¢yáµ¢ = 0, Î±áµ¢ â‰¥ 0',
      '   Solution: w = Î£áµ¢Î±áµ¢yáµ¢xáµ¢ (only support vectors have Î±áµ¢ > 0)',
      '   Decision: f(x) = sign(Î£áµ¢Î±áµ¢yáµ¢(xáµ¢Â·x) + b)',
      '',
      'ğŸ¨ VISUAL REPRESENTATION:',
      '   2D Case: Line separating two classes with maximum margin',
      '   3D Case: Plane dividing space into two regions',
      '   Support Vectors: Points exactly on the margin boundaries',
      '   Margin: "Street" between classes - widest possible separation',
      '   Non-Support Vectors: Can be moved without affecting decision boundary',
      '',
      'ğŸŒŸ SOFT MARGIN SVM (NON-SEPARABLE CASE):',
      '   Problem: Real data often not linearly separable',
      '   Solution: Allow some misclassification with penalty',
      '   Slack Variables: Î¾áµ¢ â‰¥ 0 for constraint violations',
      '   Modified Constraint: yáµ¢(wÂ·xáµ¢ + b) â‰¥ 1 - Î¾áµ¢',
      '',
      'âš–ï¸ C-PARAMETER REGULARIZATION:',
      '   Objective: minimize (1/2)||w||Â² + CÂ·Î£áµ¢Î¾áµ¢',
      '   C â†’ âˆ: Hard margin (no misclassification allowed)',
      '   C â†’ 0: Very soft margin (focus on large margin)',
      '   Trade-off: Margin width vs classification accuracy',
      '   Typical values: C âˆˆ [0.1, 100]',
      '',
      'ğŸ”® KERNEL TRICK (NON-LINEAR SVM):',
      '   Problem: Linear boundaries insufficient for complex data',
      '   Solution: Map data to higher-dimensional space',
      '   Kernel Function: K(xáµ¢, xâ±¼) = Ï†(xáµ¢)Â·Ï†(xâ±¼)',
      '   Advantage: No explicit computation of Ï†(x)',
      '',
      'ğŸ§® POPULAR KERNEL FUNCTIONS:',
      '',
      '   ğŸ“ˆ LINEAR KERNEL:',
      '   K(xáµ¢, xâ±¼) = xáµ¢Â·xâ±¼',
      '   Use: Linearly separable data, text classification',
      '',
      '   ğŸŒ€ POLYNOMIAL KERNEL:',
      '   K(xáµ¢, xâ±¼) = (Î³xáµ¢Â·xâ±¼ + r)áµˆ',
      '   Parameters: d=degree, Î³=scaling, r=offset',
      '   Use: Moderate non-linearity, image processing',
      '',
      '   ğŸ¯ RBF (RADIAL BASIS FUNCTION) KERNEL:',
      '   K(xáµ¢, xâ±¼) = exp(-Î³||xáµ¢ - xâ±¼||Â²)',
      '   Parameter: Î³ controls "influence radius"',
      '   High Î³: Tight fit (overfitting risk)',
      '   Low Î³: Smooth boundary (underfitting risk)',
      '   Use: Most popular, handles complex non-linear patterns',
      '',
      '   ğŸŒŠ SIGMOID KERNEL:',
      '   K(xáµ¢, xâ±¼) = tanh(Î³xáµ¢Â·xâ±¼ + r)',
      '   Use: Neural network-like behavior',
      '',
      'ğŸ” PRACTICAL EXAMPLE - EMAIL SPAM CLASSIFICATION:',
      '',
      '   Features: [word_count("free"), exclamation_marks, caps_ratio]',
      '   Training Data:',
      '   Email 1: [5, 3, 0.8] â†’ Spam (y=+1)',
      '   Email 2: [0, 1, 0.1] â†’ Ham (y=-1)',
      '   Email 3: [2, 0, 0.2] â†’ Ham (y=-1)',
      '',
      '   Linear SVM Result:',
      '   Hyperplane: 0.6Ã—word_count + 0.4Ã—exclamations + 0.8Ã—caps_ratio - 1.2 = 0',
      '   Support Vectors: Emails exactly on margin boundaries',
      '   New Email: [3, 2, 0.5] â†’ f(x) = sign(0.6Ã—3 + 0.4Ã—2 + 0.8Ã—0.5 - 1.2) = +1 (Spam)',
      '',
      'ğŸ­ MULTICLASS SVM:',
      '   One-vs-One (OvO): Train C(C-1)/2 binary classifiers',
      '   One-vs-Rest (OvR): Train C binary classifiers',
      '   Decision: Majority voting or highest confidence score',
      '   ECOC: Error-Correcting Output Codes for robustness',
      '',
      'ğŸ“Š ADVANTAGES:',
      '   âœ… Effective in high-dimensional spaces',
      '   âœ… Memory efficient (uses subset of training points)',
      '   âœ… Versatile (different kernels for different problems)',
      '   âœ… Works well with small datasets',
      '   âœ… Strong theoretical foundation',
      '',
      'âš ï¸ DISADVANTAGES:',
      '   âŒ No probabilistic output (unlike logistic regression)',
      '   âŒ Sensitive to feature scaling',
      '   âŒ Slow on large datasets (O(nÂ³) training complexity)',
      '   âŒ Choice of kernel and parameters crucial',
      '   âŒ No direct interpretation of feature importance',
      '',
      'ğŸ”§ HYPERPARAMETER TUNING:',
      '   C Parameter: Controls regularization strength',
      '   Gamma (RBF): Controls kernel width/influence',
      '   Kernel Selection: Try linear first, then RBF',
      '   Grid Search: Systematic parameter exploration',
      '   Cross-Validation: Prevent overfitting during tuning',
      '',
      'ğŸ“ˆ EVALUATION METRICS:',
      '   Accuracy: (TP + TN)/(TP + TN + FP + FN)',
      '   Precision/Recall: For imbalanced datasets',
      '   F1-Score: Harmonic mean of precision and recall',
      '   Support Vector Count: Indicator of model complexity',
      '   Margin Width: 2/||w|| (larger is better for generalization)',
      '',
      'ğŸ”¬ ADVANCED CONCEPTS:',
      '   Î½-SVM: Alternative formulation with Î½ parameter',
      '   One-Class SVM: Novelty/anomaly detection',
      '   SVR: Support Vector Regression for continuous targets',
      '   Sequential Minimal Optimization (SMO): Efficient training algorithm',
      '',
      'ğŸ’» IMPLEMENTATION PIPELINE:',
      '   1. Data Preprocessing: Handle missing values, encode categories',
      '   2. Feature Scaling: StandardScaler or MinMaxScaler (CRITICAL!)',
      '   3. Kernel Selection: Start with RBF, try linear for text',
      '   4. Hyperparameter Tuning: Grid search with CV',
      '   5. Model Training: Fit on training set',
      '   6. Evaluation: Test on holdout set, analyze support vectors',
      '',
      'ğŸ¯ DECISION BOUNDARY VISUALIZATION:',
      '   Linear SVM: Straight line/plane separating classes',
      '   RBF SVM: Curved, complex boundaries following data shape',
      '   Support Vectors: Highlighted points defining the boundary',
      '   Margin: Parallel lines/planes showing separation width',
      '   Misclassified Points: Inside margin or wrong side of boundary'
    ]
  },
  {
    name: 'â›°ï¸ Gradient Descent Deep Dive',
    details: [
      'ğŸ¯ DEFINITION & CORE CONCEPT:',
      '   Goal: Find minimum of cost function by iteratively moving in steepest descent direction',
      '   Key Idea: Use negative gradient to guide parameter updates',
      '   Analogy: Rolling ball down hill to find lowest point',
      '   Applications: Training neural networks, linear/logistic regression, optimization',
      '',
      'ğŸ“ MATHEMATICAL FOUNDATION:',
      '',
      'ğŸ” BASIC GRADIENT DESCENT:',
      '   Update Rule: Î¸ := Î¸ - Î±âˆ‡J(Î¸)',
      '   Where: Î¸ = parameters, Î± = learning rate, âˆ‡J(Î¸) = gradient',
      '   Gradient: âˆ‡J(Î¸) = [âˆ‚J/âˆ‚Î¸â‚, âˆ‚J/âˆ‚Î¸â‚‚, ..., âˆ‚J/âˆ‚Î¸â‚™]áµ€',
      '   Intuition: Move opposite to gradient direction (steepest ascent)',
      '',
      'ğŸ“ LEARNING RATE (Î±):',
      '   Critical Hyperparameter: Controls step size',
      '   Too Large: Overshooting, oscillation, divergence',
      '   Too Small: Slow convergence, many iterations needed',
      '   Typical Values: 0.001, 0.01, 0.1, 0.3',
      '   Adaptive Methods: Automatically adjust learning rate',
      '',
      'ğŸ¯ CONVERGENCE CONDITIONS:',
      '   Gradient Norm: ||âˆ‡J(Î¸)|| < Îµ (typically Îµ = 10â»â¶)',
      '   Parameter Change: ||Î¸áµ—âºÂ¹ - Î¸áµ—|| < Îµ',
      '   Cost Change: |J(Î¸áµ—âºÂ¹) - J(Î¸áµ—)| < Îµ',
      '   Maximum Iterations: Prevent infinite loops',
      '',
      'ğŸ”„ GRADIENT DESCENT VARIANTS:',
      '',
      'ğŸ“Š 1. BATCH GRADIENT DESCENT (BGD):',
      '   Formula: Î¸ := Î¸ - Î±(1/m)Î£áµ¢â‚Œâ‚áµ âˆ‡J(Î¸; xâ±, yâ±)',
      '   Uses: Entire dataset for each update',
      '   Pros: Stable convergence, exact gradient',
      '   Cons: Slow for large datasets, memory intensive',
      '   Best For: Small to medium datasets (m < 10,000)',
      '',
      'âš¡ 2. STOCHASTIC GRADIENT DESCENT (SGD):',
      '   Formula: Î¸ := Î¸ - Î±âˆ‡J(Î¸; xâ±, yâ±)',
      '   Uses: Single example for each update',
      '   Pros: Fast updates, can escape local minima',
      '   Cons: Noisy convergence, fluctuating cost',
      '   Best For: Large datasets, online learning',
      '',
      'ğŸ¯ 3. MINI-BATCH GRADIENT DESCENT:',
      '   Formula: Î¸ := Î¸ - Î±(1/b)Î£áµ¢âˆˆbatch âˆ‡J(Î¸; xâ±, yâ±)',
      '   Uses: Small batch (typically 32, 64, 128, 256)',
      '   Pros: Balance between BGD and SGD, vectorization',
      '   Cons: Additional hyperparameter (batch size)',
      '   Best For: Most practical applications',
      '',
      'ğŸš€ ADVANCED OPTIMIZATION ALGORITHMS:',
      '',
      'ğŸ“ˆ 4. MOMENTUM:',
      '   Velocity: vâ‚œ = Î²vâ‚œâ‚‹â‚ + Î±âˆ‡J(Î¸â‚œ)',
      '   Update: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - vâ‚œ',
      '   Parameter: Î² âˆˆ [0.8, 0.99] (momentum coefficient)',
      '   Intuition: Accumulate velocity, overcome small gradients',
      '   Benefits: Faster convergence, reduced oscillation',
      '',
      'ğŸƒ 5. NESTEROV ACCELERATED GRADIENT (NAG):',
      '   Look-ahead: Î¸Ìƒ = Î¸â‚œ - Î²vâ‚œâ‚‹â‚',
      '   Gradient: âˆ‡J(Î¸Ìƒ)',
      '   Velocity: vâ‚œ = Î²vâ‚œâ‚‹â‚ + Î±âˆ‡J(Î¸Ìƒ)',
      '   Update: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - vâ‚œ',
      '   Advantage: "Look before you leap" - anticipatory updates',
      '',
      'ğŸ›ï¸ 6. ADAGRAD (ADAPTIVE GRADIENT):',
      '   Accumulator: Gâ‚œ = Gâ‚œâ‚‹â‚ + (âˆ‡J(Î¸â‚œ))Â²',
      '   Update: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - (Î±/âˆš(Gâ‚œ + Îµ))âˆ‡J(Î¸â‚œ)',
      '   Features: Per-parameter learning rates',
      '   Problem: Learning rate decays too aggressively',
      '   Good For: Sparse features, different scales',
      '',
      'ğŸ”„ 7. RMSPROP:',
      '   Moving Average: vâ‚œ = Î²vâ‚œâ‚‹â‚ + (1-Î²)(âˆ‡J(Î¸â‚œ))Â²',
      '   Update: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - (Î±/âˆš(vâ‚œ + Îµ))âˆ‡J(Î¸â‚œ)',
      '   Parameter: Î² â‰ˆ 0.9 (decay rate)',
      '   Fix: Resolves Adagrad\'s learning rate decay issue',
      '   Creator: Geoffrey Hinton (unpublished)',
      '',
      'ğŸ§  8. ADAM (ADAPTIVE MOMENT ESTIMATION):',
      '   First Moment: mÌ‚â‚œ = mâ‚œ/(1-Î²â‚áµ—), mâ‚œ = Î²â‚mâ‚œâ‚‹â‚ + (1-Î²â‚)âˆ‡J(Î¸â‚œ)',
      '   Second Moment: vÌ‚â‚œ = vâ‚œ/(1-Î²â‚‚áµ—), vâ‚œ = Î²â‚‚vâ‚œâ‚‹â‚ + (1-Î²â‚‚)(âˆ‡J(Î¸â‚œ))Â²',
      '   Update: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - Î±(mÌ‚â‚œ/âˆš(vÌ‚â‚œ + Îµ))',
      '   Parameters: Î²â‚=0.9, Î²â‚‚=0.999, Î±=0.001, Îµ=10â»â¸',
      '   Features: Combines momentum + RMSprop, bias correction',
      '',
      'ğŸ”§ 9. ADAMW (ADAM WITH WEIGHT DECAY):',
      '   Decoupled Weight Decay: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - Î±(mÌ‚â‚œ/âˆš(vÌ‚â‚œ + Îµ) + Î»Î¸â‚œ)',
      '   Parameter: Î» = weight decay coefficient',
      '   Improvement: Better regularization than L2 in Adam',
      '   Popular: State-of-the-art for transformer training',
      '',
      'âš¡ 10. ADADELTA:',
      '   Running Average: E[gÂ²]â‚œ = ÏE[gÂ²]â‚œâ‚‹â‚ + (1-Ï)gâ‚œÂ²',
      '   Parameter Update: Î”Î¸â‚œ = -(âˆš(E[Î”Î¸Â²]â‚œâ‚‹â‚ + Îµ)/âˆš(E[gÂ²]â‚œ + Îµ))gâ‚œ',
      '   No Learning Rate: Self-adaptive, eliminates Î± hyperparameter',
      '   Robust: Less sensitive to hyperparameters',
      '',
      'ğŸ“Š PRACTICAL EXAMPLE - LINEAR REGRESSION:',
      '',
      '   Cost Function: J(Î¸) = (1/2m)Î£áµ¢(hÎ¸(xâ±) - yâ±)Â²',
      '   Gradient: âˆ‡J(Î¸â±¼) = (1/m)Î£áµ¢(hÎ¸(xâ±) - yâ±)xâ±¼â±',
      '',
      '   Initial: Î¸â‚€ = 0, Î¸â‚ = 0, Î± = 0.01',
      '   Data: (x=1,y=2), (x=2,y=4), (x=3,y=6)',
      '',
      '   Iteration 1:',
      '   h(x) = 0 + 0Ã—x = 0',
      '   Errors: [2, 4, 6]',
      '   âˆ‡J(Î¸â‚€) = (1/3)(2+4+6) = 4',
      '   âˆ‡J(Î¸â‚) = (1/3)(2Ã—1+4Ã—2+6Ã—3) = 8',
      '   Updates: Î¸â‚€ = 0 - 0.01Ã—4 = -0.04, Î¸â‚ = 0 - 0.01Ã—8 = -0.08',
      '',
      'ğŸ¨ VISUALIZATION CONCEPTS:',
      '   Cost Surface: 3D landscape with parameters as x,y axes',
      '   Gradient Vector: Arrow pointing uphill (steepest ascent)',
      '   Descent Path: Trajectory from initialization to minimum',
      '   Learning Rate Effect: Step size along gradient direction',
      '   Local vs Global Minima: Multiple valleys in cost surface',
      '',
      'ğŸ” ALGORITHM COMPARISON:',
      '',
      '   ğŸƒ CONVERGENCE SPEED:',
      '   Adam > RMSprop > Momentum > SGD > BGD',
      '',
      '   ğŸ“Š MEMORY USAGE:',
      '   BGD > Mini-batch > SGD',
      '   Adam > RMSprop > Momentum > Vanilla GD',
      '',
      '   ğŸ¯ HYPERPARAMETER SENSITIVITY:',
      '   SGD (high) > BGD > Adam > RMSprop (low)',
      '',
      '   ğŸ”§ EASE OF TUNING:',
      '   Adam (easy) > RMSprop > Momentum > SGD (hard)',
      '',
      'âš™ï¸ HYPERPARAMETER TUNING GUIDELINES:',
      '',
      '   ğŸ“ˆ LEARNING RATE STRATEGIES:',
      '   â€¢ Fixed: Constant throughout training',
      '   â€¢ Step Decay: Reduce by factor every N epochs',
      '   â€¢ Exponential Decay: Î± = Î±â‚€ Ã— e^(-kt)',
      '   â€¢ Cosine Annealing: Î± = Î±â‚€/2(1 + cos(Ï€t/T))',
      '   â€¢ Warm Restart: Periodic resets with smaller learning rates',
      '',
      '   ğŸ¯ BATCH SIZE EFFECTS:',
      '   â€¢ Small (8-32): Noisy gradients, better generalization',
      '   â€¢ Medium (64-256): Good balance, most common',
      '   â€¢ Large (512+): Stable training, may overfit',
      '',
      'âš ï¸ COMMON ISSUES & SOLUTIONS:',
      '',
      '   ğŸŒ‹ EXPLODING GRADIENTS:',
      '   Problem: Gradients become very large',
      '   Solutions: Gradient clipping, lower learning rate',
      '   Detection: NaN values, loss becomes inf',
      '',
      '   ğŸ•³ï¸ VANISHING GRADIENTS:',
      '   Problem: Gradients become very small',
      '   Solutions: Better initialization, residual connections',
      '   Common: Deep neural networks, RNNs',
      '',
      '   ğŸ¯ SADDLE POINTS:',
      '   Problem: Gradient â‰ˆ 0 but not minimum',
      '   Solutions: Momentum-based methods, noise injection',
      '   Detection: Loss plateau, slow convergence',
      '',
      '   ğŸ”„ OSCILLATION:',
      '   Problem: Parameters bounce around minimum',
      '   Solutions: Reduce learning rate, use momentum',
      '   Cause: Learning rate too high',
      '',
      'ğŸ“‹ ALGORITHM SELECTION GUIDE:',
      '',
      '   ğŸš€ GENERAL PURPOSE: Adam (good default choice)',
      '   ğŸƒ FAST PROTOTYPING: SGD with momentum',
      '   ğŸ¯ PRODUCTION SYSTEMS: AdamW with weight decay',
      '   ğŸ“Š COMPUTER VISION: SGD with momentum + learning rate scheduling',
      '   ğŸ§  NLP/TRANSFORMERS: AdamW with warm-up + cosine decay',
      '   ğŸ“ˆ SPARSE DATA: Adagrad or RMSprop',
      '',
      'ğŸ’» IMPLEMENTATION CONSIDERATIONS:',
      '   â€¢ Numerical Stability: Add small Îµ to denominators',
      '   â€¢ Vectorization: Use matrix operations for efficiency',
      '   â€¢ Memory Management: Store running averages efficiently',
      '   â€¢ Learning Rate Schedules: Implement decay strategies',
      '   â€¢ Gradient Clipping: Prevent exploding gradients',
      '   â€¢ Checkpointing: Save best parameters during training',
      '',
      'ğŸ“ˆ MONITORING & DEBUGGING:',
      '   â€¢ Plot loss curves: Training vs validation',
      '   â€¢ Track gradient norms: Detect vanishing/exploding',
      '   â€¢ Monitor learning rate: Ensure proper scheduling',
      '   â€¢ Visualize parameter updates: Check convergence',
      '   â€¢ Record convergence metrics: Time to target accuracy'
    ]
  }
];

const AICard: React.FC = () => {
  const [expanded, setExpanded] = useState<string | null>(null);
  const toggle = (name: string) => setExpanded(prev => prev === name ? null : name);

  return (
    <div className="systems-container">
      {topics.map(topic => (
        <div key={topic.name} className="system-card" onClick={() => toggle(topic.name)}>
          <div className="system-card-header">
            <h4>{topic.name}</h4>
            <span className="toggle-arrow">{expanded === topic.name ? 'â–²' : 'â–¼'}</span>
          </div>
          {expanded === topic.name && (
            <div className="system-card-details">
              <ul>
                {topic.details.map((d, i) => <li key={i}>{d}</li>)}
              </ul>
            </div>
          )}
        </div>
      ))}
    </div>
  );
};

export default AICard;
