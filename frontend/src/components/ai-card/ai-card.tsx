import React from 'react';
import { useLocation } from 'react-router-dom';


interface AITopic {
  name: string;
  details: string[];
}

const topics: AITopic[] = [
  {
    name: 'Supervised Learning',
    details: [
      ' Definition: Trains on labeled input-output pairs to learn mapping f: X  to  Y',
      ' Goal: Make accurate predictions on new, unseen data',
      '',
      ' LINEAR REGRESSION:',
      '   Formula: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ',
      '   Cost Function: MSE = (1/2m) Œ£(hŒ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)¬≤',
      '   Example: Predicting house prices based on size, location, bedrooms',
      '   Visual: Straight line fitting through data points',
      '',
      ' LOGISTIC REGRESSION:',
      '   Formula: p = 1/(1 + e^(-z)) where z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çôx‚Çô',
      '   Cost Function: J(Œ∏) = -(1/m)[Œ£y‚ÅΩ‚Å±‚Åælog(hŒ∏(x‚ÅΩ‚Å±‚Åæ)) + (1-y‚ÅΩ‚Å±‚Åæ)log(1-hŒ∏(x‚ÅΩ‚Å±‚Åæ))]',
      '   Example: Email spam detection (spam=1, not spam=0)',
      '   Visual: S-shaped sigmoid curve',
      '',
      ' SUPPORT VECTOR MACHINE (SVM):',
      '   Formula: f(x) = sign(Œ£Œ±·µ¢y·µ¢K(x·µ¢,x) + b)',
      '   Objective: max margin = 2/||w||',
      '   Kernel Trick: K(x,z) = œÜ(x)·µÄœÜ(z) (RBF: K(x,z) = exp(-Œ≥||x-z||¬≤))',
      '   Example: Image classification, text categorization',
      '   Visual: Hyperplane separating classes with maximum margin',
      '',
      ' DECISION TREES:',
      '   Split Criterion: Gini = 1 - Œ£p·µ¢¬≤ or Entropy = -Œ£p·µ¢log‚ÇÇ(p·µ¢)',
      '   Information Gain: IG = H(parent) - Œ£(|child|/|parent|)H(child)',
      '   Example: Medical diagnosis (fever>38¬∞C  to  cold vs flu)',
      '   Visual: Tree structure with if-then rules',
      '',
      ' RANDOM FOREST:',
      '   Formula: ≈∑ = (1/B)Œ£T·µ¶(x) for regression, majority vote for classification',
      '   Bootstrap: Sample with replacement, use ‚àöp features per split',
      '   Example: Credit scoring, feature importance ranking',
      '   Visual: Multiple trees voting on final prediction',
      '',
      ' NEURAL NETWORKS:',
      '   Forward Pass: aÀ° = œÉ(WÀ°aÀ°‚Åª¬π + bÀ°)',
      '   Backpropagation: ‚àÇC/‚àÇw = Œ¥·µÉÀ°‚Åª¬π·µÄ, Œ¥À° = (WÀ°‚Å∫¬π)·µÄŒ¥À°‚Å∫¬π  *  œÉ\'(zÀ°)',
      '   Activation: ReLU = max(0,x), Sigmoid = 1/(1+e‚ÅªÀ£), Tanh = (eÀ£-e‚ÅªÀ£)/(eÀ£+e‚ÅªÀ£)',
      '   Example: Image recognition, natural language processing',
      '   Visual: Layered network of interconnected nodes',
      '',
      ' K-NEAREST NEIGHBORS (KNN):',
      '   Distance: Euclidean = ‚àöŒ£(x·µ¢-y·µ¢)¬≤, Manhattan = Œ£|x·µ¢-y·µ¢|',
      '   Prediction: Majority vote (classification) or average (regression) of k neighbors',
      '   Example: Recommendation systems, pattern recognition',
      '   Visual: Points clustered around similar neighbors',
      '',
      ' EVALUATION METRICS:',
      '   Accuracy = (TP+TN)/(TP+TN+FP+FN)',
      '   Precision = TP/(TP+FP), Recall = TP/(TP+FN)',
      '   F1-Score = 2√ó(Precision√óRecall)/(Precision+Recall)',
      '   ROC-AUC: Area under Receiver Operating Characteristic curve'
    ]
  },
  {
    name: 'Unsupervised Learning',
    details: [
      ' Definition: Discovers hidden patterns in unlabeled data without target variables',
      ' Goal: Find structure, reduce dimensions, group similar data points',
      '',
      ' K-MEANS CLUSTERING:',
      '   Algorithm: Minimize WCSS = Œ£Œ£||x·µ¢ - Œº‚±º||¬≤ where Œº‚±º is centroid j',
      '   Steps: 1) Initialize k centroids 2) Assign points 3) Update centroids 4) Repeat',
      '   Distance: Euclidean = ‚àöŒ£(x·µ¢-y·µ¢)¬≤',
      '   Example: Customer segmentation, market research, image compression',
      '   Visual: Points grouped around k cluster centers',
      '',
      ' HIERARCHICAL CLUSTERING:',
      '   Agglomerative: Bottom-up, merge closest clusters',
      '   Divisive: Top-down, split clusters recursively',
      '   Linkage: Single (min), Complete (max), Average, Ward (minimize variance)',
      '   Example: Phylogenetic trees, social network analysis',
      '   Visual: Dendrogram showing cluster hierarchy',
      '',
      ' DBSCAN (Density-Based):',
      '   Core Point: |N(p)| ‚â• minPts within Œµ radius',
      '   Border Point: In Œµ-neighborhood of core point',
      '   Noise Point: Neither core nor border',
      '   Example: Anomaly detection, irregular cluster shapes',
      '   Visual: Dense regions connected, outliers as noise',
      '',
      ' PRINCIPAL COMPONENT ANALYSIS (PCA):',
      '   Formula: Y = XW where W are eigenvectors of covariance matrix',
      '   Variance Explained: Œª·µ¢/Œ£Œª‚±º for eigenvalue Œª·µ¢',
      '   Steps: 1) Standardize 2) Covariance matrix 3) Eigendecomposition 4) Project',
      '   Example: Image compression, data visualization, feature reduction',
      '   Visual: Data projected onto principal component axes',
      '',
      ' t-SNE (t-Distributed Stochastic Neighbor Embedding):',
      '   High-D Similarity: p‚±º|·µ¢ = exp(-||x·µ¢-x‚±º||¬≤/2œÉ·µ¢¬≤)/Œ£‚Çñ‚â†·µ¢exp(-||x·µ¢-x‚Çñ||¬≤/2œÉ·µ¢¬≤)',
      '   Low-D Similarity: q·µ¢‚±º = (1+||y·µ¢-y‚±º||¬≤)‚Åª¬π/Œ£‚Çñ‚â†‚Çó(1+||y‚Çñ-y‚Çó||¬≤)‚Åª¬π',
      '   Cost: KL(P||Q) = Œ£·µ¢Œ£‚±ºp·µ¢‚±ºlog(p·µ¢‚±º/q·µ¢‚±º)',
      '   Example: High-dimensional data visualization, gene expression',
      '   Visual: Non-linear embedding preserving local structure',
      '',
      ' ASSOCIATION RULES (Market Basket):',
      '   Support: sup(A) = |A|/|D| (frequency of itemset A)',
      '   Confidence: conf(A to B) = sup(A‚à™B)/sup(A)',
      '   Lift: lift(A to B) = conf(A to B)/sup(B)',
      '   Apriori Algorithm: Generate frequent itemsets, extract rules',
      '   Example: "People who buy bread also buy butter" (grocery stores)',
      '   Visual: Network of item associations with strength indicators',
      '',
      ' GAUSSIAN MIXTURE MODELS (GMM):',
      '   Formula: p(x) = Œ£‚ÇñœÄ‚Çñùí©(x|Œº‚Çñ,Œ£‚Çñ) where œÄ‚Çñ are mixing coefficients',
      '   EM Algorithm: E-step (responsibilities), M-step (parameters)',
      '   Log-likelihood: ‚Ñì = Œ£·µ¢log(Œ£‚ÇñœÄ‚Çñùí©(x·µ¢|Œº‚Çñ,Œ£‚Çñ))',
      '   Example: Image segmentation, density estimation',
      '   Visual: Overlapping Gaussian distributions forming clusters',
      '',
      ' UNIFORM MANIFOLD APPROXIMATION (UMAP):',
      '   Theory: Riemannian manifold learning with topological data analysis',
      '   Fuzzy Simplicial Sets: Probabilistic topology representation',
      '   Optimization: Cross-entropy between high/low dimensional representations',
      '   Example: Single-cell genomics, large-scale data visualization',
      '   Visual: Preserves both local and global structure better than t-SNE',
      '',
      ' EVALUATION METRICS:',
      '   Silhouette Score: (b-a)/max(a,b) where a=intra, b=inter cluster distance',
      '   Davies-Bouldin Index: (1/k)Œ£·µ¢max‚±º‚â†·µ¢(œÉ·µ¢+œÉ‚±º)/d(c·µ¢,c‚±º) (lower is better)',
      '   Calinski-Harabasz: Between-cluster variance / Within-cluster variance',
      '   Elbow Method: Plot WCSS vs k, find "elbow" point'
    ]
  },
  {
    name: 'Reinforcement Learning',
    details: [
      ' Definition: Agent learns optimal actions through trial-and-error interactions with environment',
      ' Goal: Maximize cumulative reward over time through optimal policy œÄ*',
      ' Core Elements: State (S), Action (A), Reward (R), Policy (œÄ), Value (V)',
      '',
      ' MARKOV DECISION PROCESS (MDP):',
      '   Components: <S, A, P, R, Œ≥> (States, Actions, Transitions, Rewards, Discount)',
      '   Bellman Equation: V*(s) = max_a Œ£s\' P(s\'|s,a)[R(s,a,s\') + Œ≥V*(s\')]',
      '   Policy: œÄ(a|s) = probability of taking action a in state s',
      '   Visual: State-action diagram with transition probabilities',
      '',
      ' Q-LEARNING (Model-Free):',
      '   Update Rule: Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥max_a\'Q(s\',a\') - Q(s,a)]',
      '   Œµ-Greedy: Choose random action with probability Œµ, else argmax_a Q(s,a)',
      '   Convergence: Guaranteed if all state-action pairs visited infinitely often',
      '   Example: Game playing (Pac-Man), robot navigation',
      '   Visual: Q-table with state-action values, policy derived from max Q-values',
      '',
      ' SARSA (State-Action-Reward-State-Action):',
      '   Update Rule: Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥Q(s\',a\') - Q(s,a)]',
      '   On-Policy: Updates based on actual policy being followed',
      '   Difference from Q-Learning: Uses actual next action a\' instead of max',
      '   Example: Safe robot control, conservative exploration',
      '   Visual: Agent follows policy while learning, more conservative updates',
      '',
      ' DEEP Q-NETWORKS (DQN):',
      '   Neural Network: Q(s,a;Œ∏) ‚âà Q*(s,a) where Œ∏ are network parameters',
      '   Loss Function: L(Œ∏) = E[(r + Œ≥max_a\'Q(s\',a\';Œ∏‚Åª) - Q(s,a;Œ∏))¬≤]',
      '   Experience Replay: Store transitions in buffer, sample mini-batches',
      '   Target Network: Œ∏‚Åª updated periodically to stabilize training',
      '   Example: Atari games, complex state spaces',
      '   Visual: Neural network approximating Q-function for high-dimensional states',
      '',
      ' POLICY GRADIENT METHODS:',
      '   REINFORCE: ‚àáJ(Œ∏) = E[‚àálog œÄ(a|s;Œ∏) Q^œÄ(s,a)]',
      '   Actor-Critic: Actor updates policy, Critic estimates value function',
      '   Advantage: A(s,a) = Q(s,a) - V(s) (reduces variance)',
      '   Example: Continuous control, robotics, complex action spaces',
      '   Visual: Direct policy optimization without value function intermediary',
      '',
      ' PROXIMAL POLICY OPTIMIZATION (PPO):',
      '   Objective: L^CLIP(Œ∏) = E[min(r_t(Œ∏)√Ç_t, clip(r_t(Œ∏),1-Œµ,1+Œµ)√Ç_t)]',
      '   Ratio: r_t(Œ∏) = œÄ_Œ∏(a_t|s_t)/œÄ_Œ∏_old(a_t|s_t)',
      '   Clipping: Prevents large policy updates, maintains stability',
      '   Example: OpenAI Five (Dota 2), robotics, continuous control',
      '   Visual: Clipped objective function preventing destructive updates',
      '',
      ' ACTOR-CRITIC METHODS:',
      '   Actor: ‚àáJ(Œ∏) = E[‚àálog œÄ(a|s;Œ∏) A(s,a)]',
      '   Critic: V(s;w) ‚âà V^œÄ(s), updated via TD learning',
      '   A3C: Asynchronous Advantage Actor-Critic with multiple workers',
      '   A2C: Synchronous version of A3C',
      '   Example: Complex environments, parallel training',
      '   Visual: Two networks - actor (policy) and critic (value) working together',
      '',
      ' DEEP DETERMINISTIC POLICY GRADIENT (DDPG):',
      '   Deterministic Policy: Œº(s;Œ∏^Œº) instead of stochastic œÄ(a|s)',
      '   Critic Update: L = E[(r + Œ≥Q(s\',Œº(s\');Œ∏^Q) - Q(s,a;Œ∏^Q))¬≤]',
      '   Actor Update: ‚àáJ = E[‚àá_a Q(s,a;Œ∏^Q)|_{a=Œº(s)} ‚àáŒº(s;Œ∏^Œº)]',
      '   Exploration: Add noise to deterministic policy',
      '   Example: Continuous control tasks, robotic manipulation',
      '   Visual: Deterministic policy mapping states directly to actions',
      '',
      ' MULTI-ARMED BANDITS:',
      '   UCB1: Select action with highest UCB_t(a) = QÃÑ_t(a) + c‚àö(ln t/N_t(a))',
      '   Thompson Sampling: Sample from posterior distribution of action values',
      '   Œµ-Greedy: Explore randomly with probability Œµ',
      '   Example: A/B testing, recommendation systems, online advertising',
      '   Visual: Arms (actions) with unknown reward distributions',
      '',
      ' EVALUATION METRICS:',
      '   Cumulative Reward: G_t = Œ£_{k=0}^‚àû Œ≥^k R_{t+k+1}',
      '   Sample Efficiency: Learning speed (episodes to convergence)',
      '   Policy Performance: Average reward per episode',
      '   Exploration Efficiency: Coverage of state-action space'
    ]
  },
  {
    name: 'Agentic AI vs Generative AI',
    details: [
      ' AGENTIC AI (Goal-Oriented, Action-Taking):',
      '   Definition: AI systems that can take autonomous actions to achieve specific goals',
      '   Core Capability: Decision-making, planning, and executing actions in environments',
      '   Architecture: Agent + Environment + Action Space + Reward Function',
      '   Learning: Through interaction, trial-and-error, reinforcement learning',
      '   Examples: Autonomous vehicles, trading bots, game-playing AI (AlphaGo)',
      '   Visual: Agent interacting with environment, taking actions based on observations',
      '',
      ' GENERATIVE AI (Content Creation):',
      '   Definition: AI systems that create new content (text, images, audio, code)',
      '   Core Capability: Pattern recognition and synthesis from training data',
      '   Architecture: Encoder-Decoder, Transformers, GANs, Diffusion Models',
      '   Learning: Through large datasets, supervised/unsupervised learning',
      '   Examples: ChatGPT, DALL-E, Midjourney, GitHub Copilot, Stable Diffusion',
      '   Visual: Neural network generating new content from learned patterns',
      '',
      ' KEY DIFFERENCES:',
      '',
      ' PURPOSE & GOALS:',
      '   Agentic AI: Optimize outcomes, maximize rewards, achieve objectives',
      '   Generative AI: Create realistic, diverse, high-quality content',
      '',
      ' INTERACTION MODEL:',
      '   Agentic AI: Interactive, real-time decision making in dynamic environments',
      '   Generative AI: One-shot or iterative content generation from prompts',
      '',
      ' TRAINING APPROACH:',
      '   Agentic AI: Reinforcement Learning, Online Learning, Trial-and-Error',
      '   Generative AI: Supervised Learning, Self-Supervised, Large-Scale Pretraining',
      '',
      ' ENVIRONMENT:',
      '   Agentic AI: Dynamic, reactive environments (games, real world, simulations)',
      '   Generative AI: Static datasets, text corpora, image collections',
      '',
      ' EVALUATION METRICS:',
      '   Agentic AI: Reward/utility maximization, success rate, efficiency',
      '   Generative AI: Quality, diversity, coherence, human preference',
      '',
      ' FEEDBACK LOOP:',
      '   Agentic AI: Immediate environment feedback, reward signals',
      '   Generative AI: Human feedback, preference learning, RLHF',
      '',
      ' REAL-TIME REQUIREMENTS:',
      '   Agentic AI: Often requires real-time decision making',
      '   Generative AI: Can operate with longer inference times for quality',
      '',
      ' EXPLORATION vs EXPLOITATION:',
      '   Agentic AI: Critical balance between exploring new strategies and exploiting known good ones',
      '   Generative AI: Exploration through randomness/sampling for diversity',
      '',
      ' EMERGING HYBRID APPROACHES:',
      '   Agent + LLM: Language agents that can reason and take actions',
      '   Generative Agents: AI agents that can generate plans and content',
      '   Examples: ChatGPT with plugins, AutoGPT, LangChain agents',
      '   Visual: Integration of both paradigms for comprehensive AI systems',
      '',
      ' PRACTICAL APPLICATIONS:',
      '   Agentic AI: Robotics, autonomous systems, algorithmic trading, game AI',
      '   Generative AI: Content creation, code generation, art, writing assistance',
      '   Hybrid: AI assistants, creative collaborators, intelligent automation'
    ]
  },
  {
    name: 'Entropy vs Gini Index',
    details: [
      ' DECISION TREE SPLIT CRITERIA COMPARISON:',
      '   Purpose: Both measure impurity/uncertainty in data splits for decision trees',
      '   Goal: Find optimal splits that maximize information gain and purity',
      '',
      ' ENTROPY (Information Theory Based):',
      '   Formula: H(S) = -Œ£·µ¢ p·µ¢ √ó log‚ÇÇ(p·µ¢)',
      '   Range: 0 (pure) to log‚ÇÇ(n) where n = number of classes',
      '   Binary Classification: H(S) = -p‚ÇÅlog‚ÇÇ(p‚ÇÅ) - p‚ÇÇlog‚ÇÇ(p‚ÇÇ)',
      '   Maximum: log‚ÇÇ(2) = 1 for binary, occurs when p‚ÇÅ = p‚ÇÇ = 0.5',
      '   Interpretation: Average number of bits needed to encode class information',
      '   Example: For [50% Class A, 50% Class B]: H = -0.5√ólog‚ÇÇ(0.5) - 0.5√ólog‚ÇÇ(0.5) = 1',
      '',
      ' GINI INDEX (Probability Based):',
      '   Formula: Gini(S) = 1 - Œ£·µ¢ p·µ¢¬≤',
      '   Range: 0 (pure) to 0.5 (maximum impurity for binary)',
      '   Binary Classification: Gini(S) = 1 - p‚ÇÅ¬≤ - p‚ÇÇ¬≤',
      '   Maximum: 0.5 for binary, occurs when p‚ÇÅ = p‚ÇÇ = 0.5',
      '   Interpretation: Probability of misclassifying a randomly chosen element',
      '   Example: For [50% Class A, 50% Class B]: Gini = 1 - 0.5¬≤ - 0.5¬≤ = 0.5',
      '',
      ' KEY DIFFERENCES:',
      '',
      ' MATHEMATICAL PROPERTIES:',
      '   Entropy: Logarithmic function, more sensitive to probability changes',
      '   Gini: Quadratic function, computationally simpler (no logarithms)',
      '   Entropy: Higher penalty for very uneven splits',
      '   Gini: More balanced penalty across probability ranges',
      '',
      ' COMPUTATIONAL COMPLEXITY:',
      '   Entropy: Requires logarithm calculation (more expensive)',
      '   Gini: Simple arithmetic operations (faster)',
      '   Performance: Gini typically 2-3x faster to compute',
      '',
      ' SENSITIVITY ANALYSIS:',
      '   Entropy: More sensitive to small probability changes near 0 or 1',
      '   Gini: More stable, less sensitive to extreme probabilities',
      '   Split Selection: Entropy tends to favor more balanced splits',
      '   Practical Impact: Usually produce similar tree structures',
      '',
      ' PRACTICAL EXAMPLES:',
      '',
      '   Dataset: [80% Class A, 20% Class B]',
      '   Entropy: H = -0.8√ólog‚ÇÇ(0.8) - 0.2√ólog‚ÇÇ(0.2) = 0.722',
      '   Gini: G = 1 - 0.8¬≤ - 0.2¬≤ = 1 - 0.64 - 0.04 = 0.32',
      '',
      '   Dataset: [90% Class A, 10% Class B]',
      '   Entropy: H = -0.9√ólog‚ÇÇ(0.9) - 0.1√ólog‚ÇÇ(0.1) = 0.469',
      '   Gini: G = 1 - 0.9¬≤ - 0.1¬≤ = 1 - 0.81 - 0.01 = 0.18',
      '',
      ' INFORMATION GAIN CALCULATION:',
      '   Information Gain: IG = H(parent) - Œ£(|child|/|parent|) √ó H(child)',
      '   Gini Gain: GG = Gini(parent) - Œ£(|child|/|parent|) √ó Gini(child)',
      '   Both aim to maximize gain (reduce impurity after split)',
      '',
      ' ALGORITHM PREFERENCES:',
      '   C4.5/C5.0: Uses Entropy (information gain ratio)',
      '   CART: Uses Gini Index by default',
      '   Random Forest: Often uses Gini for speed',
      '   scikit-learn: Gini default, Entropy available',
      '',
      ' DECISION GUIDELINES:',
      '   Use Entropy: When interpretability matters, theoretical analysis',
      '   Use Gini: When speed is critical, large datasets, production systems',
      '   Performance: Both typically yield similar accuracy',
      '   Default Choice: Gini for most practical applications'
    ]
  },
  {
    name: 'Linear Regression Deep Dive',
    details: [
      ' DEFINITION & PURPOSE:',
      '   Goal: Find the best linear relationship between input features (X) and target (y)',
      '   Assumption: Linear relationship exists between variables',
      '   Output: Continuous numerical predictions',
      '',
      ' MATHEMATICAL FOUNDATION:',
      '',
      ' SIMPLE LINEAR REGRESSION (1 Feature):',
      '   Model: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œµ',
      '   Œ≤‚ÇÄ: y-intercept (bias term)',
      '   Œ≤‚ÇÅ: slope (weight/coefficient)',
      '   Œµ: error term (noise)',
      '   Prediction: ≈∑ = Œ≤‚ÇÄ + Œ≤‚ÇÅx',
      '',
      ' MULTIPLE LINEAR REGRESSION (n Features):',
      '   Model: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ',
      '   Matrix Form: y = XŒ≤ + Œµ',
      '   X: [1, x‚ÇÅ, x‚ÇÇ, ..., x‚Çô] (design matrix with bias column)',
      '   Œ≤: [Œ≤‚ÇÄ, Œ≤‚ÇÅ, Œ≤‚ÇÇ, ..., Œ≤‚Çô]·µÄ (parameter vector)',
      '',
      ' COST FUNCTION (Mean Squared Error):',
      '   MSE = (1/2m) Œ£·µ¢‚Çå‚ÇÅ·µê (hŒ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)¬≤',
      '   hŒ∏(x‚ÅΩ‚Å±‚Åæ) = Œ∏‚ÇÄ + Œ∏‚ÇÅx‚ÇÅ‚ÅΩ‚Å±‚Åæ + ... + Œ∏‚Çôx‚Çô‚ÅΩ‚Å±‚Åæ',
      '   m: number of training examples',
      '   Goal: minimize J(Œ∏) = MSE',
      '',
      ' ANALYTICAL SOLUTION (Normal Equation):',
      '   Œ∏ = (X·µÄX)‚Åª¬πX·µÄy',
      '   Derivation: ‚àáJ(Œ∏) = 0',
      '   ‚àÇJ/‚àÇŒ∏ = X·µÄXŒ∏ - X·µÄy = 0',
      '   Pros: Exact solution, no learning rate needed',
      '   Cons: O(n¬≥) complexity, requires matrix inversion',
      '',
      ' GRADIENT DESCENT APPROACH:',
      '',
      ' BATCH GRADIENT DESCENT:',
      '   Update Rule: Œ∏‚±º := Œ∏‚±º - Œ±(‚àÇJ/‚àÇŒ∏‚±º)',
      '   Partial Derivative: ‚àÇJ/‚àÇŒ∏‚±º = (1/m) Œ£·µ¢‚Çå‚ÇÅ·µê (hŒ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)x‚±º‚ÅΩ‚Å±‚Åæ',
      '   Œ±: learning rate (typically 0.01 to 0.3)',
      '   Convergence: When ||‚àáJ(Œ∏)|| < tolerance',
      '',
      ' STOCHASTIC GRADIENT DESCENT (SGD):',
      '   Update per example: Œ∏‚±º := Œ∏‚±º - Œ±(hŒ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)x‚±º‚ÅΩ‚Å±‚Åæ',
      '   Faster updates, more noisy convergence',
      '   Good for large datasets (m > 10,000)',
      '',
      ' VISUAL REPRESENTATION:',
      '   Simple Linear: Straight line y = mx + b on 2D plot',
      '   Multiple Linear: Hyperplane in n-dimensional space',
      '   Cost Function: Convex bowl shape (single global minimum)',
      '   Gradient Descent: Ball rolling down the cost surface',
      '',
      ' PRACTICAL EXAMPLE - House Price Prediction:',
      '',
      '   Features: Size (sq ft), Bedrooms, Age, Location Score',
      '   Model: Price = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óSize + Œ≤‚ÇÇ√óBedrooms + Œ≤‚ÇÉ√óAge + Œ≤‚ÇÑ√óLocation',
      '',
      '   Sample Data:',
      '   House 1: Size=1500, Beds=3, Age=10, Loc=8  to  Price=$300K',
      '   House 2: Size=2000, Beds=4, Age=5, Loc=9  to  Price=$450K',
      '',
      '   After Training:',
      '   Price = 50000 + 150√óSize + 10000√óBeds - 2000√óAge + 5000√óLoc',
      '   Interpretation: Each sq ft adds $150, each bedroom adds $10K',
      '',
      ' ASSUMPTIONS & REQUIREMENTS:',
      '   1. Linearity: Relationship between X and y is linear',
      '   2. Independence: Observations are independent',
      '   3. Homoscedasticity: Constant variance of residuals',
      '   4. Normality: Residuals are normally distributed',
      '   5. No Multicollinearity: Features not highly correlated',
      '',
      ' COMMON PROBLEMS & SOLUTIONS:',
      '   Overfitting: Use regularization (Ridge/Lasso)',
      '   Multicollinearity: Remove correlated features, use PCA',
      '   Non-linearity: Feature engineering, polynomial features',
      '   Outliers: Robust regression, outlier detection',
      '',
      ' FEATURE ENGINEERING:',
      '   Polynomial Features: x‚ÇÅ, x‚ÇÇ, x‚ÇÅ¬≤, x‚ÇÇ¬≤, x‚ÇÅx‚ÇÇ',
      '   Interaction Terms: x‚ÇÅ √ó x‚ÇÇ, x‚ÇÅ √ó x‚ÇÉ',
      '   Log Transform: log(x) for exponential relationships',
      '   Normalization: (x - Œº)/œÉ for different scales',
      '',
      ' EVALUATION METRICS:',
      '   MSE = (1/n) Œ£(y·µ¢ - ≈∑·µ¢)¬≤',
      '   RMSE = ‚àöMSE (same units as target)',
      '   MAE = (1/n) Œ£|y·µ¢ - ≈∑·µ¢| (robust to outliers)',
      '   R¬≤ = 1 - (SS_res/SS_tot) (proportion of variance explained)',
      '',
      ' IMPLEMENTATION STEPS:',
      '   1. Data Preprocessing: Handle missing values, normalize',
      '   2. Feature Selection: Choose relevant features',
      '   3. Train-Test Split: Typically 80-20 or 70-30',
      '   4. Model Training: Fit using Normal Equation or GD',
      '   5. Evaluation: Calculate metrics on test set',
      '   6. Validation: Cross-validation for robustness'
    ]
  },
  {
    name: 'Logistic Regression Deep Dive',
    details: [
      ' DEFINITION & PURPOSE:',
      '   Goal: Predict probability of binary/categorical outcomes (classification)',
      '   Output: Probability between 0 and 1',
      '   Decision Boundary: Linear separation in feature space',
      '   Applications: Email spam, medical diagnosis, marketing response',
      '',
      ' FUNDAMENTAL CONCEPT:',
      '   Problem: Linear regression outputs unbounded values (-‚àû to +‚àû)',
      '   Solution: Map linear output to probability using sigmoid function',
      '   Advantage: Probabilistic interpretation of predictions',
      '',
      ' SIGMOID FUNCTION (LOGISTIC FUNCTION):',
      '   Formula: œÉ(z) = 1/(1 + e^(-z))',
      '   Input: z = Œ∏‚ÇÄ + Œ∏‚ÇÅx‚ÇÅ + Œ∏‚ÇÇx‚ÇÇ + ... + Œ∏‚Çôx‚Çô',
      '   Output Range: (0, 1)',
      '   Properties: S-shaped curve, differentiable, monotonic',
      '',
      ' SIGMOID CURVE CHARACTERISTICS:',
      '   At z = 0: œÉ(0) = 1/(1 + e‚Å∞) = 1/2 = 0.5',
      '   As z  to  +‚àû: œÉ(z)  to  1',
      '   As z  to  -‚àû: œÉ(z)  to  0',
      '   Derivative: œÉ\'(z) = œÉ(z)(1 - œÉ(z))',
      '   Maximum slope at z = 0',
      '',
      ' LOGISTIC REGRESSION MODEL:',
      '   Hypothesis: h_Œ∏(x) = œÉ(Œ∏·µÄx) = 1/(1 + e^(-Œ∏·µÄx))',
      '   Prediction: ≈∑ = 1 if h_Œ∏(x) ‚â• 0.5, else 0',
      '   Decision Boundary: Œ∏·µÄx = 0 (where h_Œ∏(x) = 0.5)',
      '',
      ' PROBABILITY INTERPRETATION:',
      '   P(y=1|x;Œ∏) = h_Œ∏(x) = sigmoid(Œ∏·µÄx)',
      '   P(y=0|x;Œ∏) = 1 - h_Œ∏(x)',
      '   Odds Ratio: P(y=1)/P(y=0) = e^(Œ∏·µÄx)',
      '   Log-Odds (Logit): ln(P(y=1)/P(y=0)) = Œ∏·µÄx',
      '',
      ' COST FUNCTION (LOG-LIKELIHOOD):',
      '   Cannot use MSE (non-convex for sigmoid)',
      '   Use Maximum Likelihood Estimation (MLE)',
      '   Likelihood: L(Œ∏) = ‚àè·µ¢‚Çå‚ÇÅ·µê P(y‚ÅΩ‚Å±‚Åæ|x‚ÅΩ‚Å±‚Åæ;Œ∏)',
      '   Log-Likelihood: ‚Ñì(Œ∏) = Œ£·µ¢‚Çå‚ÇÅ·µê [y‚ÅΩ‚Å±‚Åælog(h_Œ∏(x‚ÅΩ‚Å±‚Åæ)) + (1-y‚ÅΩ‚Å±‚Åæ)log(1-h_Œ∏(x‚ÅΩ‚Å±‚Åæ))]',
      '',
      ' COST FUNCTION FORMULA:',
      '   J(Œ∏) = -(1/m) Œ£·µ¢‚Çå‚ÇÅ·µê [y‚ÅΩ‚Å±‚Åælog(h_Œ∏(x‚ÅΩ‚Å±‚Åæ)) + (1-y‚ÅΩ‚Å±‚Åæ)log(1-h_Œ∏(x‚ÅΩ‚Å±‚Åæ))]',
      '   Individual Cost: cost(h_Œ∏(x),y) = -ylog(h_Œ∏(x)) - (1-y)log(1-h_Œ∏(x))',
      '   Properties: Convex, differentiable, penalizes wrong predictions heavily',
      '',
      ' GRADIENT DESCENT:',
      '   Partial Derivative: ‚àÇJ/‚àÇŒ∏‚±º = (1/m) Œ£·µ¢‚Çå‚ÇÅ·µê (h_Œ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)x‚±º‚ÅΩ‚Å±‚Åæ',
      '   Update Rule: Œ∏‚±º := Œ∏‚±º - Œ±(‚àÇJ/‚àÇŒ∏‚±º)',
      '   Note: Same form as linear regression but h_Œ∏(x) is sigmoid!',
      '   Learning Rate: Typically 0.01 to 1.0',
      '',
      ' DERIVATION OF GRADIENT:',
      '   ‚àÇœÉ/‚àÇz = œÉ(z)(1-œÉ(z))',
      '   ‚àÇJ/‚àÇŒ∏‚±º = -(1/m) Œ£·µ¢ [y‚ÅΩ‚Å±‚Åæ/h_Œ∏(x‚ÅΩ‚Å±‚Åæ) - (1-y‚ÅΩ‚Å±‚Åæ)/(1-h_Œ∏(x‚ÅΩ‚Å±‚Åæ))] √ó ‚àÇh_Œ∏/‚àÇŒ∏‚±º',
      '   Simplifies to: (1/m) Œ£·µ¢ (h_Œ∏(x‚ÅΩ‚Å±‚Åæ) - y‚ÅΩ‚Å±‚Åæ)x‚±º‚ÅΩ‚Å±‚Åæ',
      '',
      ' VISUAL REPRESENTATION:',
      '   1D Feature: S-curve separating two classes',
      '   2D Features: Linear decision boundary line',
      '   nD Features: Hyperplane in n-dimensional space',
      '   Cost Surface: Convex bowl (single global minimum)',
      '   Probability Contours: Smooth gradients from 0 to 1',
      '',
      'üìß PRACTICAL EXAMPLE - Email Spam Detection:',
      '',
      '   Features: Word count ("free"), exclamation marks, caps ratio',
      '   Model: P(spam) = œÉ(Œ∏‚ÇÄ + Œ∏‚ÇÅ√ó"free_count" + Œ∏‚ÇÇ√óexclamations + Œ∏‚ÇÉ√ócaps_ratio)',
      '',
      '   Sample Training:',
      '   Email 1: free=5, !=3, caps=0.8  to  Spam (y=1)',
      '   Email 2: free=0, !=1, caps=0.1  to  Not Spam (y=0)',
      '',
      '   After Training:',
      '   Œ∏ = [-2.0, 1.5, 0.8, 2.0]',
      '   New Email: free=3, !=2, caps=0.6',
      '   z = -2.0 + 1.5√ó3 + 0.8√ó2 + 2.0√ó0.6 = 4.3',
      '   P(spam) = 1/(1 + e^(-4.3)) = 0.986  to  98.6% spam probability',
      '',
      ' MULTICLASS CLASSIFICATION:',
      '   One-vs-Rest (OvR): Train n binary classifiers',
      '   One-vs-One (OvO): Train n(n-1)/2 classifiers',
      '   Softmax Regression: Direct multiclass extension',
      '   Softmax: P(y=k|x) = e^(Œ∏‚Çñ·µÄx) / Œ£‚±ºe^(Œ∏‚±º·µÄx)',
      '',
      ' ASSUMPTIONS & REQUIREMENTS:',
      '   1. Linear relationship between logit and features',
      '   2. Independence of observations',
      '   3. No severe multicollinearity',
      '   4. Large sample size (at least 10 events per parameter)',
      '   5. No extreme outliers',
      '',
      ' COMMON ISSUES & SOLUTIONS:',
      '   Perfect Separation: Use regularization (L1/L2)',
      '   Multicollinearity: Remove correlated features',
      '   Outliers: Robust scaling, outlier detection',
      '   Imbalanced Data: SMOTE, class weights, threshold tuning',
      '',
      ' REGULARIZATION:',
      '   L1 (Lasso): J(Œ∏) + ŒªŒ£|Œ∏‚±º| (feature selection)',
      '   L2 (Ridge): J(Œ∏) + ŒªŒ£Œ∏‚±º¬≤ (prevents overfitting)',
      '   Elastic Net: Combination of L1 and L2',
      '',
      ' EVALUATION METRICS:',
      '   Accuracy = (TP + TN)/(TP + TN + FP + FN)',
      '   Precision = TP/(TP + FP)',
      '   Recall = TP/(TP + FN)',
      '   F1-Score = 2√ó(Precision√óRecall)/(Precision+Recall)',
      '   AUC-ROC: Area under ROC curve',
      '   Log-Loss: -(1/n)Œ£[y·µ¢log(p·µ¢) + (1-y·µ¢)log(1-p·µ¢)]',
      '',
      ' DECISION THRESHOLD TUNING:',
      '   Default: 0.5 threshold',
      '   High Precision: Increase threshold (fewer false positives)',
      '   High Recall: Decrease threshold (fewer false negatives)',
      '   ROC Curve: Plot TPR vs FPR for all thresholds',
      '',
      ' IMPLEMENTATION STEPS:',
      '   1. Data Preprocessing: Handle missing values, encode categoricals',
      '   2. Feature Scaling: Standardize for better convergence',
      '   3. Train-Test Split: Stratified split for balanced classes',
      '   4. Model Training: Gradient descent or Newton-Raphson',
      '   5. Threshold Tuning: Optimize based on business requirements',
      '   6. Evaluation: Multiple metrics, cross-validation'
    ]
  },
  {
    name: ' Softmax Function Deep Dive',
    details: [
      ' MATHEMATICAL FOUNDATION:',
      '   Formula: œÉ(z_i) = e^(z_i) / Œ£(j=1 to K) e^(z_j)',
      '   Where: z_i = input for class i, K = total classes',
      '   Output: Probability distribution where Œ£ œÉ(z_i) = 1',
      '   Properties: All values ‚àà [0,1], differentiable, smooth',
      '',
      'üéõÔ∏è TEMPERATURE PARAMETER:',
      '   Modified Formula: œÉ(z_i) = e^(z_i/T) / Œ£(j=1 to K) e^(z_j/T)',
      '   T  to  0: Becomes argmax (one-hot distribution)',
      '   T  to  ‚àû: Becomes uniform distribution (1/K for all classes)',
      '   T = 1: Standard softmax',
      '   Use Cases: Controlling confidence, knowledge distillation',
      '',
      ' PRACTICAL EXAMPLE - IMAGE CLASSIFICATION:',
      '   Raw Model Outputs (logits): [Cat: 2.0, Dog: 1.0, Bird: 0.1]',
      '   Exponentials: [e^2.0 = 7.39, e^1.0 = 2.72, e^0.1 = 1.11]',
      '   Sum: 7.39 + 2.72 + 1.11 = 11.22',
      '   Probabilities: [Cat: 65.9%, Dog: 24.2%, Bird: 9.9%]',
      '   Interpretation: Model is most confident about "Cat"',
      '',
      'üî• KEY PROPERTIES:',
      '   1. Probability Distribution: All outputs sum to 1',
      '   2. Exponential Amplification: Emphasizes maximum values',
      '   3. Differentiable: Smooth gradients for backpropagation',
      '   4. Monotonic: Preserves relative ordering of inputs',
      '   5. Scale Invariant: Adding constant to all inputs unchanged output',
      '',
      ' CROSS-ENTROPY LOSS CONNECTION:',
      '   Loss Function: L = -Œ£(i=1 to K) y_i √ó log(œÉ(z_i))',
      '   Gradient: ‚àÇL/‚àÇz_i = œÉ(z_i) - y_i',
      '   Beautiful Property: Gradient = predicted_prob - true_prob',
      '   Interpretation: Directly optimizes probability predictions',
      '',
      ' NUMERICAL STABILITY:',
      '   Problem: Large values cause overflow (e^1000 = ‚àû)',
      '   Solution: Subtract maximum value before computation',
      '   Stable Formula: z\' = z - max(z), then apply softmax to z\'',
      '   Mathematical Equivalence: Result unchanged, but prevents overflow',
      '   Implementation: Always use this trick in production code',
      '',
      ' APPLICATIONS:',
      '   ‚Ä¢ Multi-class Classification: Final layer of neural networks',
      '   ‚Ä¢ Attention Mechanisms: Transformer models, seq2seq',
      '   ‚Ä¢ Reinforcement Learning: Action probability distributions',
      '   ‚Ä¢ Natural Language Processing: Next word prediction',
      '   ‚Ä¢ Computer Vision: Object detection, semantic segmentation',
      '   ‚Ä¢ Recommendation Systems: Item probability scoring',
      '',
      ' SOFTMAX vs SIGMOID:',
      '   Sigmoid: Binary classification, independent probabilities',
      '   Softmax: Multi-class classification, mutually exclusive probabilities',
      '   Sigmoid: œÉ(z) = 1/(1 + e^(-z)), output ‚àà [0,1]',
      '   Softmax: Generalizes sigmoid to multiple classes',
      '   Use Case: Sigmoid for multi-label, Softmax for multi-class',
      '',
      ' IMPLEMENTATION EXAMPLE:',
      '   def softmax(z):',
      '       # Numerical stability',
      '       z_shifted = z - np.max(z)',
      '       exp_z = np.exp(z_shifted)',
      '       return exp_z / np.sum(exp_z)',
      '   ',
      '   # Usage in neural network',
      '   logits = model(x)  # Raw outputs',
      '   probabilities = softmax(logits)  # Convert to probabilities',
      '   prediction = np.argmax(probabilities)  # Get predicted class'
    ]
  },
  {
    name: 'Support Vector Machine (SVM) Deep Dive',
    details: [
      ' DEFINITION & CORE CONCEPT:',
      '   Goal: Find optimal hyperplane that separates classes with maximum margin',
      '   Key Idea: Maximize distance between decision boundary and closest points',
      '   Support Vectors: Data points closest to the hyperplane (critical for model)',
      '   Applications: Text classification, image recognition, bioinformatics',
      '',
      ' MATHEMATICAL FOUNDATION:',
      '',
      ' LINEAR SVM (SEPARABLE CASE):',
      '   Decision Function: f(x) = sign(w¬∑x + b)',
      '   Hyperplane Equation: w¬∑x + b = 0',
      '   Where: w = weight vector (normal to hyperplane)',
      '         b = bias term (shifts hyperplane)',
      '         x = input feature vector',
      '',
      ' MARGIN CALCULATION:',
      '   Geometric Margin: Œ≥ = |w¬∑x + b|/||w||',
      '   Functional Margin: Œ≥ÃÉ = y(w¬∑x + b)',
      '   Maximum Margin: M = 2/||w|| (distance between support vectors)',
      '   Constraint: y·µ¢(w¬∑x·µ¢ + b) ‚â• 1 for all training points',
      '',
      ' OPTIMIZATION PROBLEM (PRIMAL FORM):',
      '   Objective: minimize (1/2)||w||¬≤ subject to y·µ¢(w¬∑x·µ¢ + b) ‚â• 1',
      '   Quadratic Programming: Convex optimization problem',
      '   Lagrangian: L = (1/2)||w||¬≤ - Œ£·µ¢Œ±·µ¢[y·µ¢(w¬∑x·µ¢ + b) - 1]',
      '   KKT Conditions: Œ±·µ¢ ‚â• 0, Œ±·µ¢[y·µ¢(w¬∑x·µ¢ + b) - 1] = 0',
      '',
      ' DUAL FORMULATION:',
      '   Objective: maximize Œ£·µ¢Œ±·µ¢ - (1/2)Œ£·µ¢Œ£‚±ºŒ±·µ¢Œ±‚±ºy·µ¢y‚±º(x·µ¢¬∑x‚±º)',
      '   Subject to: Œ£·µ¢Œ±·µ¢y·µ¢ = 0, Œ±·µ¢ ‚â• 0',
      '   Solution: w = Œ£·µ¢Œ±·µ¢y·µ¢x·µ¢ (only support vectors have Œ±·µ¢ > 0)',
      '   Decision: f(x) = sign(Œ£·µ¢Œ±·µ¢y·µ¢(x·µ¢¬∑x) + b)',
      '',
      ' VISUAL REPRESENTATION:',
      '   2D Case: Line separating two classes with maximum margin',
      '   3D Case: Plane dividing space into two regions',
      '   Support Vectors: Points exactly on the margin boundaries',
      '   Margin: "Street" between classes - widest possible separation',
      '   Non-Support Vectors: Can be moved without affecting decision boundary',
      '',
      ' SOFT MARGIN SVM (NON-SEPARABLE CASE):',
      '   Problem: Real data often not linearly separable',
      '   Solution: Allow some misclassification with penalty',
      '   Slack Variables: Œæ·µ¢ ‚â• 0 for constraint violations',
      '   Modified Constraint: y·µ¢(w¬∑x·µ¢ + b) ‚â• 1 - Œæ·µ¢',
      '',
      ' C-PARAMETER REGULARIZATION:',
      '   Objective: minimize (1/2)||w||¬≤ + C¬∑Œ£·µ¢Œæ·µ¢',
      '   C  to  ‚àû: Hard margin (no misclassification allowed)',
      '   C  to  0: Very soft margin (focus on large margin)',
      '   Trade-off: Margin width vs classification accuracy',
      '   Typical values: C ‚àà [0.1, 100]',
      '',
      ' KERNEL TRICK (NON-LINEAR SVM):',
      '   Problem: Linear boundaries insufficient for complex data',
      '   Solution: Map data to higher-dimensional space',
      '   Kernel Function: K(x·µ¢, x‚±º) = œÜ(x·µ¢)¬∑œÜ(x‚±º)',
      '   Advantage: No explicit computation of œÜ(x)',
      '',
      ' POPULAR KERNEL FUNCTIONS:',
      '',
      '    LINEAR KERNEL:',
      '   K(x·µ¢, x‚±º) = x·µ¢¬∑x‚±º',
      '   Use: Linearly separable data, text classification',
      '',
      '   POLYNOMIAL KERNEL:',
      '   K(x·µ¢, x‚±º) = (Œ≥x·µ¢¬∑x‚±º + r)·µà',
      '   Parameters: d=degree, Œ≥=scaling, r=offset',
      '   Use: Moderate non-linearity, image processing',
      '',
      '    RBF (RADIAL BASIS FUNCTION) KERNEL:',
      '   K(x·µ¢, x‚±º) = exp(-Œ≥||x·µ¢ - x‚±º||¬≤)',
      '   Parameter: Œ≥ controls "influence radius"',
      '   High Œ≥: Tight fit (overfitting risk)',
      '   Low Œ≥: Smooth boundary (underfitting risk)',
      '   Use: Most popular, handles complex non-linear patterns',
      '',
      '   SIGMOID KERNEL:',
      '   K(x·µ¢, x‚±º) = tanh(Œ≥x·µ¢¬∑x‚±º + r)',
      '   Use: Neural network-like behavior',
      '',
      ' PRACTICAL EXAMPLE - EMAIL SPAM CLASSIFICATION:',
      '',
      '   Features: [word_count("free"), exclamation_marks, caps_ratio]',
      '   Training Data:',
      '   Email 1: [5, 3, 0.8]  to  Spam (y=+1)',
      '   Email 2: [0, 1, 0.1]  to  Ham (y=-1)',
      '   Email 3: [2, 0, 0.2]  to  Ham (y=-1)',
      '',
      '   Linear SVM Result:',
      '   Hyperplane: 0.6√óword_count + 0.4√óexclamations + 0.8√ócaps_ratio - 1.2 = 0',
      '   Support Vectors: Emails exactly on margin boundaries',
      '   New Email: [3, 2, 0.5]  to  f(x) = sign(0.6√ó3 + 0.4√ó2 + 0.8√ó0.5 - 1.2) = +1 (Spam)',
      '',
      ' MULTICLASS SVM:',
      '   One-vs-One (OvO): Train C(C-1)/2 binary classifiers',
      '   One-vs-Rest (OvR): Train C binary classifiers',
      '   Decision: Majority voting or highest confidence score',
      '   ECOC: Error-Correcting Output Codes for robustness',
      '',
      ' ADVANTAGES:',
      '   Effective in high-dimensional spaces',
      '   Memory efficient (uses subset of training points)',
      '   Versatile (different kernels for different problems)',
      '   Works well with small datasets',
      '   Strong theoretical foundation',
      '',
      ' DISADVANTAGES:',
      '   No probabilistic output (unlike logistic regression)',
      '   Sensitive to feature scaling',
      '   Slow on large datasets (O(n¬≥) training complexity)',
      '   Choice of kernel and parameters crucial',
      '   No direct interpretation of feature importance',
      '',
      ' HYPERPARAMETER TUNING:',
      '   C Parameter: Controls regularization strength',
      '   Gamma (RBF): Controls kernel width/influence',
      '   Kernel Selection: Try linear first, then RBF',
      '   Grid Search: Systematic parameter exploration',
      '   Cross-Validation: Prevent overfitting during tuning',
      '',
      ' EVALUATION METRICS:',
      '   Accuracy: (TP + TN)/(TP + TN + FP + FN)',
      '   Precision/Recall: For imbalanced datasets',
      '   F1-Score: Harmonic mean of precision and recall',
      '   Support Vector Count: Indicator of model complexity',
      '   Margin Width: 2/||w|| (larger is better for generalization)',
      '',
      ' ADVANCED CONCEPTS:',
      '   ŒΩ-SVM: Alternative formulation with ŒΩ parameter',
      '   One-Class SVM: Novelty/anomaly detection',
      '   SVR: Support Vector Regression for continuous targets',
      '   Sequential Minimal Optimization (SMO): Efficient training algorithm',
      '',
      ' IMPLEMENTATION PIPELINE:',
      '   1. Data Preprocessing: Handle missing values, encode categories',
      '   2. Feature Scaling: StandardScaler or MinMaxScaler (CRITICAL!)',
      '   3. Kernel Selection: Start with RBF, try linear for text',
      '   4. Hyperparameter Tuning: Grid search with CV',
      '   5. Model Training: Fit on training set',
      '   6. Evaluation: Test on holdout set, analyze support vectors',
      '',
      ' DECISION BOUNDARY VISUALIZATION:',
      '   Linear SVM: Straight line/plane separating classes',
      '   RBF SVM: Curved, complex boundaries following data shape',
      '   Support Vectors: Highlighted points defining the boundary',
      '   Margin: Parallel lines/planes showing separation width',
      '   Misclassified Points: Inside margin or wrong side of boundary'
    ]
  },
  {
    name: 'Gradient Descent Deep Dive',
    details: [
      ' DEFINITION & CORE CONCEPT:',
      '   Goal: Find minimum of cost function by iteratively moving in steepest descent direction',
      '   Key Idea: Use negative gradient to guide parameter updates',
      '   Analogy: Rolling ball down hill to find lowest point',
      '   Applications: Training neural networks, linear/logistic regression, optimization',
      '',
      ' MATHEMATICAL FOUNDATION:',
      '',
      ' BASIC GRADIENT DESCENT:',
      '   Update Rule: Œ∏ := Œ∏ - Œ±‚àáJ(Œ∏)',
      '   Where: Œ∏ = parameters, Œ± = learning rate, ‚àáJ(Œ∏) = gradient',
      '   Gradient: ‚àáJ(Œ∏) = [‚àÇJ/‚àÇŒ∏‚ÇÅ, ‚àÇJ/‚àÇŒ∏‚ÇÇ, ..., ‚àÇJ/‚àÇŒ∏‚Çô]·µÄ',
      '   Intuition: Move opposite to gradient direction (steepest ascent)',
      '',
      ' LEARNING RATE (Œ±):',
      '   Critical Hyperparameter: Controls step size',
      '   Too Large: Overshooting, oscillation, divergence',
      '   Too Small: Slow convergence, many iterations needed',
      '   Typical Values: 0.001, 0.01, 0.1, 0.3',
      '   Adaptive Methods: Automatically adjust learning rate',
      '',
      ' CONVERGENCE CONDITIONS:',
      '   Gradient Norm: ||‚àáJ(Œ∏)|| < Œµ (typically Œµ = 10‚Åª‚Å∂)',
      '   Parameter Change: ||Œ∏·µó‚Å∫¬π - Œ∏·µó|| < Œµ',
      '   Cost Change: |J(Œ∏·µó‚Å∫¬π) - J(Œ∏·µó)| < Œµ',
      '   Maximum Iterations: Prevent infinite loops',
      '',
      ' GRADIENT DESCENT VARIANTS:',
      '',
      ' 1. BATCH GRADIENT DESCENT (BGD):',
      '   Formula: Œ∏ := Œ∏ - Œ±(1/m)Œ£·µ¢‚Çå‚ÇÅ·µê ‚àáJ(Œ∏; x‚Å±, y‚Å±)',
      '   Uses: Entire dataset for each update',
      '   Pros: Stable convergence, exact gradient',
      '   Cons: Slow for large datasets, memory intensive',
      '   Best For: Small to medium datasets (m < 10,000)',
      '',
      ' 2. STOCHASTIC GRADIENT DESCENT (SGD):',
      '   Formula: Œ∏ := Œ∏ - Œ±‚àáJ(Œ∏; x‚Å±, y‚Å±)',
      '   Uses: Single example for each update',
      '   Pros: Fast updates, can escape local minima',
      '   Cons: Noisy convergence, fluctuating cost',
      '   Best For: Large datasets, online learning',
      '',
      ' 3. MINI-BATCH GRADIENT DESCENT:',
      '   Formula: Œ∏ := Œ∏ - Œ±(1/b)Œ£·µ¢‚ààbatch ‚àáJ(Œ∏; x‚Å±, y‚Å±)',
      '   Uses: Small batch (typically 32, 64, 128, 256)',
      '   Pros: Balance between BGD and SGD, vectorization',
      '   Cons: Additional hyperparameter (batch size)',
      '   Best For: Most practical applications',
      '',
      ' ADVANCED OPTIMIZATION ALGORITHMS:',
      '',
      ' 4. MOMENTUM:',
      '   Velocity: v‚Çú = Œ≤v‚Çú‚Çã‚ÇÅ + Œ±‚àáJ(Œ∏‚Çú)',
      '   Update: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - v‚Çú',
      '   Parameter: Œ≤ ‚àà [0.8, 0.99] (momentum coefficient)',
      '   Intuition: Accumulate velocity, overcome small gradients',
      '   Benefits: Faster convergence, reduced oscillation',
      '',
      ' 5. NESTEROV ACCELERATED GRADIENT (NAG):',
      '   Look-ahead: Œ∏ÃÉ = Œ∏‚Çú - Œ≤v‚Çú‚Çã‚ÇÅ',
      '   Gradient: ‚àáJ(Œ∏ÃÉ)',
      '   Velocity: v‚Çú = Œ≤v‚Çú‚Çã‚ÇÅ + Œ±‚àáJ(Œ∏ÃÉ)',
      '   Update: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - v‚Çú',
      '   Advantage: "Look before you leap" - anticipatory updates',
      '',
      'üéõÔ∏è 6. ADAGRAD (ADAPTIVE GRADIENT):',
      '   Accumulator: G‚Çú = G‚Çú‚Çã‚ÇÅ + (‚àáJ(Œ∏‚Çú))¬≤',
      '   Update: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - (Œ±/‚àö(G‚Çú + Œµ))‚àáJ(Œ∏‚Çú)',
      '   Features: Per-parameter learning rates',
      '   Problem: Learning rate decays too aggressively',
      '   Good For: Sparse features, different scales',
      '',
      ' 7. RMSPROP:',
      '   Moving Average: v‚Çú = Œ≤v‚Çú‚Çã‚ÇÅ + (1-Œ≤)(‚àáJ(Œ∏‚Çú))¬≤',
      '   Update: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - (Œ±/‚àö(v‚Çú + Œµ))‚àáJ(Œ∏‚Çú)',
      '   Parameter: Œ≤ ‚âà 0.9 (decay rate)',
      '   Fix: Resolves Adagrad\'s learning rate decay issue',
      '   Creator: Geoffrey Hinton (unpublished)',
      '',
      ' 8. ADAM (ADAPTIVE MOMENT ESTIMATION):',
      '   First Moment: mÃÇ‚Çú = m‚Çú/(1-Œ≤‚ÇÅ·µó), m‚Çú = Œ≤‚ÇÅm‚Çú‚Çã‚ÇÅ + (1-Œ≤‚ÇÅ)‚àáJ(Œ∏‚Çú)',
      '   Second Moment: vÃÇ‚Çú = v‚Çú/(1-Œ≤‚ÇÇ·µó), v‚Çú = Œ≤‚ÇÇv‚Çú‚Çã‚ÇÅ + (1-Œ≤‚ÇÇ)(‚àáJ(Œ∏‚Çú))¬≤',
      '   Update: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - Œ±(mÃÇ‚Çú/‚àö(vÃÇ‚Çú + Œµ))',
      '   Parameters: Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999, Œ±=0.001, Œµ=10‚Åª‚Å∏',
      '   Features: Combines momentum + RMSprop, bias correction',
      '',
      ' 9. ADAMW (ADAM WITH WEIGHT DECAY):',
      '   Decoupled Weight Decay: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - Œ±(mÃÇ‚Çú/‚àö(vÃÇ‚Çú + Œµ) + ŒªŒ∏‚Çú)',
      '   Parameter: Œª = weight decay coefficient',
      '   Improvement: Better regularization than L2 in Adam',
      '   Popular: State-of-the-art for transformer training',
      '',
      ' 10. ADADELTA:',
      '   Running Average: E[g¬≤]‚Çú = œÅE[g¬≤]‚Çú‚Çã‚ÇÅ + (1-œÅ)g‚Çú¬≤',
      '   Parameter Update: ŒîŒ∏‚Çú = -(‚àö(E[ŒîŒ∏¬≤]‚Çú‚Çã‚ÇÅ + Œµ)/‚àö(E[g¬≤]‚Çú + Œµ))g‚Çú',
      '   No Learning Rate: Self-adaptive, eliminates Œ± hyperparameter',
      '   Robust: Less sensitive to hyperparameters',
      '',
      ' PRACTICAL EXAMPLE - LINEAR REGRESSION:',
      '',
      '   Cost Function: J(Œ∏) = (1/2m)Œ£·µ¢(hŒ∏(x‚Å±) - y‚Å±)¬≤',
      '   Gradient: ‚àáJ(Œ∏‚±º) = (1/m)Œ£·µ¢(hŒ∏(x‚Å±) - y‚Å±)x‚±º‚Å±',
      '',
      '   Initial: Œ∏‚ÇÄ = 0, Œ∏‚ÇÅ = 0, Œ± = 0.01',
      '   Data: (x=1,y=2), (x=2,y=4), (x=3,y=6)',
      '',
      '   Iteration 1:',
      '   h(x) = 0 + 0√óx = 0',
      '   Errors: [2, 4, 6]',
      '   ‚àáJ(Œ∏‚ÇÄ) = (1/3)(2+4+6) = 4',
      '   ‚àáJ(Œ∏‚ÇÅ) = (1/3)(2√ó1+4√ó2+6√ó3) = 8',
      '   Updates: Œ∏‚ÇÄ = 0 - 0.01√ó4 = -0.04, Œ∏‚ÇÅ = 0 - 0.01√ó8 = -0.08',
      '',
      ' VISUALIZATION CONCEPTS:',
      '   Cost Surface: 3D landscape with parameters as x,y axes',
      '   Gradient Vector: Arrow pointing uphill (steepest ascent)',
      '   Descent Path: Trajectory from initialization to minimum',
      '   Learning Rate Effect: Step size along gradient direction',
      '   Local vs Global Minima: Multiple valleys in cost surface',
      '',
      ' ALGORITHM COMPARISON:',
      '',
      '   CONVERGENCE SPEED:',
      '   Adam > RMSprop > Momentum > SGD > BGD',
      '',
      '    MEMORY USAGE:',
      '   BGD > Mini-batch > SGD',
      '   Adam > RMSprop > Momentum > Vanilla GD',
      '',
      '    HYPERPARAMETER SENSITIVITY:',
      '   SGD (high) > BGD > Adam > RMSprop (low)',
      '',
      '   EASE OF TUNING:',
      '   Adam (easy) > RMSprop > Momentum > SGD (hard)',
      '',
      ' HYPERPARAMETER TUNING GUIDELINES:',
      '',
      '    LEARNING RATE STRATEGIES:',
      '   ‚Ä¢ Fixed: Constant throughout training',
      '   ‚Ä¢ Step Decay: Reduce by factor every N epochs',
      '   ‚Ä¢ Exponential Decay: Œ± = Œ±‚ÇÄ √ó e^(-kt)',
      '   ‚Ä¢ Cosine Annealing: Œ± = Œ±‚ÇÄ/2(1 + cos(œÄt/T))',
      '   ‚Ä¢ Warm Restart: Periodic resets with smaller learning rates',
      '',
      '    BATCH SIZE EFFECTS:',
      '   ‚Ä¢ Small (8-32): Noisy gradients, better generalization',
      '   ‚Ä¢ Medium (64-256): Good balance, most common',
      '   ‚Ä¢ Large (512+): Stable training, may overfit',
      '',
      ' COMMON ISSUES & SOLUTIONS:',
      '',
      '   EXPLODING GRADIENTS:',
      '   Problem: Gradients become very large',
      '   Solutions: Gradient clipping, lower learning rate',
      '   Detection: NaN values, loss becomes inf',
      '',
      '   VANISHING GRADIENTS:',
      '   Problem: Gradients become very small',
      '   Solutions: Better initialization, residual connections',
      '   Common: Deep neural networks, RNNs',
      '',
      '    SADDLE POINTS:',
      '   Problem: Gradient ‚âà 0 but not minimum',
      '   Solutions: Momentum-based methods, noise injection',
      '   Detection: Loss plateau, slow convergence',
      '',
      '   OSCILLATION:',
      '   Problem: Parameters bounce around minimum',
      '   Solutions: Reduce learning rate, use momentum',
      '   Cause: Learning rate too high',
      '',
      ' ALGORITHM SELECTION GUIDE:',
      '',
      '    GENERAL PURPOSE: Adam (good default choice)',
      '   FAST PROTOTYPING: SGD with momentum',
      '    PRODUCTION SYSTEMS: AdamW with weight decay',
      '    COMPUTER VISION: SGD with momentum + learning rate scheduling',
      '    NLP/TRANSFORMERS: AdamW with warm-up + cosine decay',
      '    SPARSE DATA: Adagrad or RMSprop',
      '',
      ' IMPLEMENTATION CONSIDERATIONS:',
      '   ‚Ä¢ Numerical Stability: Add small Œµ to denominators',
      '   ‚Ä¢ Vectorization: Use matrix operations for efficiency',
      '   ‚Ä¢ Memory Management: Store running averages efficiently',
      '   ‚Ä¢ Learning Rate Schedules: Implement decay strategies',
      '   ‚Ä¢ Gradient Clipping: Prevent exploding gradients',
      '   ‚Ä¢ Checkpointing: Save best parameters during training',
      '',
      ' MONITORING & DEBUGGING:',
      '   ‚Ä¢ Plot loss curves: Training vs validation',
      '   ‚Ä¢ Track gradient norms: Detect vanishing/exploding',
      '   ‚Ä¢ Monitor learning rate: Ensure proper scheduling',
      '   ‚Ä¢ Visualize parameter updates: Check convergence',
      '   ‚Ä¢ Record convergence metrics: Time to target accuracy'
    ]
  }
];

const AICard: React.FC = () => {
  const location = useLocation();
  const topicIdMap: Record<string, string> = {
    'Supervised Learning': 'supervised-learning',
    'Unsupervised Learning': 'unsupervised-learning',
    'Reinforcement Learning': 'reinforcement-learning',
    'Agentic AI vs Generative AI': 'agentic-vs-generative-ai',
    'Entropy vs Gini Index': 'entropy-vs-gini',
    'Linear Regression Deep Dive': 'linear-regression',
    'Logistic Regression Deep Dive': 'logistic-regression',
    'Softmax Function Deep Dive': 'softmax-function',
    'Support Vector Machine (SVM) Deep Dive': 'svm-deep-dive',
    'Gradient Descent Deep Dive': 'gradient-descent',
  };

  const activeHash = location.hash?.replace('#', '') || '';
  const activeTopic =
    topics.find((topic) => topicIdMap[topic.name] === activeHash) || topics[0];

  const buildGroups = (details: string[]) => {
    const groups: { title: string | null; items: string[] }[] = [];
    let currentGroup: { title: string | null; items: string[] } | null = null;

    details.forEach((raw) => {
      const detail = raw.trim();
      if (!detail) return;

      if (detail.endsWith(':')) {
        currentGroup = { title: detail.slice(0, -1), items: [] };
        groups.push(currentGroup);
        return;
      }

      if (!currentGroup) {
        groups.push({ title: null, items: [detail] });
        return;
      }

      currentGroup.items.push(detail);
    });

    return groups;
  };

  const groupedDetails = buildGroups(activeTopic.details);

  return (
    <div className="systems-container">
      <div className="content-panel" id={topicIdMap[activeTopic.name]}>
        <div className="content-panel-header">
          <h1>{activeTopic.name}</h1>
          <p className="content-panel-breadcrumb">
            AI Concepts / {activeTopic.name}
          </p>
        </div>
        <ul className="content-panel-list">
          {groupedDetails.map((group, index) =>
            group.title ? (
              <li key={`${group.title}-${index}`}>
                <span className="content-panel-section">{group.title}</span>
                {group.items.length > 0 && (
                  <ul className="content-panel-sublist">
                    {group.items.map((item, itemIndex) => (
                      <li key={`${group.title}-${itemIndex}`}>{item}</li>
                    ))}
                  </ul>
                )}
              </li>
            ) : (
              group.items.map((item, itemIndex) => (
                <li key={`item-${index}-${itemIndex}`}>{item}</li>
              ))
            )
          )}
        </ul>
      </div>
    </div>
  );
};

export default AICard;
